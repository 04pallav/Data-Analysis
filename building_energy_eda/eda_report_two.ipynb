{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook documents initial attempts to create a machine learning model to predict energy consumption from weather data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Approach\n",
    "\n",
    "Based on initial explorations of the data, there is considerable variance between buildings and in different seasons. Therefore, my approach will be to develop four models for each building, one for each season. If even more accurate results are desired, it would be possible to develop one model for each month. Even with four models for each building, I can run a building through the models in a matter of seconds on my personal machine. Run time should not be an issue with these models. \n",
    "\n",
    "This notebook will explore a linear model and a Random Forest. When starting a machine learning project, these are my two \"go-to\" models to try first. The linear model is extremely simple but can demonstrate impressive results if the underlying data\n",
    "is indeed linear. The Random Forest model is an ensemble model that can capture complex relationships within a dataset. There are numerous benefits to a Random Forest including that it performs feature selection for you (no need to remove highly correlated variables) and it can return feature importances. The Random Forest model therefore has some amount of interpretability and the trees themselves can be displayed. Further work should explore the use of deep neural networks as these are able to capture extremely complex relationships. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from dateutil import parser\n",
    "from tpot import TPOTRegressor\n",
    "import tensorflow as tf\n",
    "import feather\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2013-10-16 00:15:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8253754b40ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'python_data/f-APS_weather.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2013-10-16 00:15:00'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('python_data/f-APS_weather.csv')\n",
    "type(df['timestamp'])\n",
    "float(df.ix[1, 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "dt = [datetime.datetime.strptime(df.ix[index, 'timestamp'], \"%Y-%m-%d %H:%M:%S\") for index, _ in enumerate(df['timestamp'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_time = min(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seconds = [(time.mktime(date.timetuple()) - time.mktime(min_time.timetuple())) for date in dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[900.0, 1800.0, 2700.0, 3600.0, 4500.0, 5400.0, 6300.0, 7200.0, 8100.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seconds[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model_utilities import get_features_labels\n",
    "import autoreload\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[4:5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "features, labels = get_features_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26496, 26)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "raw_df = get_features_labels(df, raw_df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model_utilities import complete_model\n",
    "\n",
    "season_results_df, overall_df, feature_import_df = complete_model('python_data/f-SRP_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>rmse</th>\n",
       "      <th>rsquared</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring</td>\n",
       "      <td>1.689232</td>\n",
       "      <td>0.978956</td>\n",
       "      <td>2.920326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summer</td>\n",
       "      <td>2.484125</td>\n",
       "      <td>0.970367</td>\n",
       "      <td>3.551882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fall</td>\n",
       "      <td>1.832783</td>\n",
       "      <td>0.975973</td>\n",
       "      <td>3.108708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>winter</td>\n",
       "      <td>1.713177</td>\n",
       "      <td>0.967346</td>\n",
       "      <td>3.138956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season      rmse  rsquared      mape\n",
       "0  spring  1.689232  0.978956  2.920326\n",
       "1  summer  2.484125  0.970367  3.551882\n",
       "2    fall  1.832783  0.975973  3.108708\n",
       "3  winter  1.713177  0.967346  3.138956"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "season_results_df, overall_df, feature_import_df = complete_model('python_data/f-SRP_weather.csv', analysis_col = 'cleaned_energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>rmse</th>\n",
       "      <th>rsquared</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring</td>\n",
       "      <td>1.67776</td>\n",
       "      <td>0.979194</td>\n",
       "      <td>2.911513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summer</td>\n",
       "      <td>2.69075</td>\n",
       "      <td>0.974863</td>\n",
       "      <td>4.040891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fall</td>\n",
       "      <td>1.88989</td>\n",
       "      <td>0.975417</td>\n",
       "      <td>4.465956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>winter</td>\n",
       "      <td>1.71011</td>\n",
       "      <td>0.967432</td>\n",
       "      <td>3.131587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season     rmse  rsquared      mape\n",
       "0  spring  1.67776  0.979194  2.911513\n",
       "1  summer  2.69075  0.974863  4.040891\n",
       "2    fall  1.88989  0.975417  4.465956\n",
       "3  winter  1.71011  0.967432  3.131587"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "season_results_df, overall_df, feature_import_df = complete_model('python_data/f-SDGE_weather.csv', analysis_col = 'cleaned_energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>rmse</th>\n",
       "      <th>rsquared</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring</td>\n",
       "      <td>0.498303</td>\n",
       "      <td>0.981390</td>\n",
       "      <td>5.578518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summer</td>\n",
       "      <td>0.639487</td>\n",
       "      <td>0.979589</td>\n",
       "      <td>7.083157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fall</td>\n",
       "      <td>0.637176</td>\n",
       "      <td>0.976998</td>\n",
       "      <td>7.319905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>winter</td>\n",
       "      <td>0.479478</td>\n",
       "      <td>0.983263</td>\n",
       "      <td>5.514479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season      rmse  rsquared      mape\n",
       "0  spring  0.498303  0.981390  5.578518\n",
       "1  summer  0.639487  0.979589  7.083157\n",
       "2    fall  0.637176  0.976998  7.319905\n",
       "3  winter  0.479478  0.983263  5.514479"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "season_results_df, overall_df, feature_import_df = complete_model('python_data/f-SMUD_weather.csv', analysis_col = 'cleaned_energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>rmse</th>\n",
       "      <th>rsquared</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring</td>\n",
       "      <td>9.873657</td>\n",
       "      <td>0.962414</td>\n",
       "      <td>6.309575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summer</td>\n",
       "      <td>13.348563</td>\n",
       "      <td>0.962132</td>\n",
       "      <td>7.438432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fall</td>\n",
       "      <td>9.517504</td>\n",
       "      <td>0.973071</td>\n",
       "      <td>5.786981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>winter</td>\n",
       "      <td>6.107994</td>\n",
       "      <td>0.978810</td>\n",
       "      <td>4.623303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season       rmse  rsquared      mape\n",
       "0  spring   9.873657  0.962414  6.309575\n",
       "1  summer  13.348563  0.962132  7.438432\n",
       "2    fall   9.517504  0.973071  5.786981\n",
       "3  winter   6.107994  0.978810  4.623303"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Data Preparation\n",
    "\n",
    "As the data is already relatively clean, the preparation steps consist of segmenting the data by season and then extracting the relevant features. The data is then put into a format (numpy array) acceptable for machine learning models in skikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Function that takes in a dataframe, season and returns the features, X, and labels, Y, as numpy arrays. \n",
    "# The function segments the data by the required season and can return the dates \n",
    "# associated with the data as well as the column names to use for determining feature importances. \n",
    "seasons = ['spring', 'summer', 'fall', 'winter']\n",
    "\n",
    "def get_features_labels(df, season = 'summer', return_dates = False, names = False):\n",
    "\n",
    "    # Get months and days for subsetting and use for additional features\n",
    "    months = []\n",
    "    days = []\n",
    "    # Extract dates from dataframe\n",
    "    dates = list(df['timestamp'])\n",
    "    # Create list of only month\n",
    "    [months.append(date.split('-')[1]) for date in dates]\n",
    "    months = list(map(int, months))\n",
    "    ## Create list of only days\n",
    "    [days.append(date.split('-')[2][0:2]) for date in dates]\n",
    "    days = list(map(int, days))\n",
    "    # Add the months and days to the dataframe\n",
    "    df['month'] = months\n",
    "    df['day'] = days\n",
    "    \n",
    "    # Define seasons\n",
    "    spring = [3, 4, 5]\n",
    "    summer = [6, 7, 8]\n",
    "    fall = [9, 10, 11]\n",
    "    winter = [12, 1, 2]\n",
    "    \n",
    "    # Extract only the relevant months\n",
    "    if season.lower() == 'spring':\n",
    "        df = df[df['month'].isin(spring)]\n",
    "    elif season.lower() == 'summer':\n",
    "        df = df[df['month'].isin(summer)]\n",
    "    elif season.lower() == 'fall':\n",
    "        df = df[df['month'].isin(fall)]\n",
    "    elif season.lower() == 'winter':\n",
    "        df = df[df['month'].isin(winter)]\n",
    "    else:\n",
    "        print('Choose a valid season')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Create column of days since start of season\n",
    "    df['season_day'] = ((df['month'] -min(df['month'])) * 30) + df['day']\n",
    "    # Need to treat month 12 slightly differently\n",
    "    # .ix used for mixed indexing, .iloc used for integer indexing, .loc used for name indexing\n",
    "    df.ix[list(df[df['month'] == 12].index), 'season_day'] = df['day']\n",
    "\n",
    "    # Extract the dates for later use in analysis and plotting\n",
    "    dates = np.array(df['timestamp'])\n",
    "    \n",
    "    # Drop the columns that are not related to time or weather\n",
    "    df = df.drop(['timestamp', 'elec_cons', 'elec_cons_imp', 'pow_dem', 'cleaned_energy', 'anom_flag',\n",
    "             'anom_missed_flag'], axis = 1)\n",
    "\n",
    "    # One_hot encoding of categorical variables\n",
    "    df = pd.get_dummies(df, columns = ['sun_rise_set', 'biz_day', 'day_of_week', 'week_day_end'])\n",
    "   \n",
    "    # Get targets: cleaned electricity\n",
    "    y = np.array(df['forecast'])\n",
    "    \n",
    "    \n",
    "    # Drop the target column\n",
    "    df = (df.drop('forecast', axis = 1))\n",
    "    \n",
    "    # Get columns to find feature importances\n",
    "    col_names = list(df.columns)\n",
    "    \n",
    "    # Convert to np array\n",
    "    df = np.array(df)\n",
    "    \n",
    "    # Create a min max scaler to get all features between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Transform features to between 0 and 1\n",
    "    X = scaler.fit_transform(df)\n",
    "    \n",
    "    # Return the features and labels as numpy arrays\n",
    "    if names and return_dates:\n",
    "        return X, y, dates, col_names\n",
    "    \n",
    "    elif names:\n",
    "        return col_names\n",
    "    \n",
    "    elif return_dates:\n",
    "        return X, y, dates\n",
    "    \n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Function to create fake data from a clean dataframe\n",
    "def get_random_variants(clean_df):\n",
    "    \n",
    "    # Copy the dataframe\n",
    "    noise_df = clean_df.copy()\n",
    "    # Add noise to the weather columns\n",
    "    col_for_noise = ['ghi', 'dif', 'temp', 'rh', 'pwat', 'ws', 'forecast']\n",
    "    n_points = clean_df.shape[0]\n",
    "    \n",
    "    # Add a random amount of noise to the selected columns\n",
    "    for col in col_for_noise:\n",
    "        std_dev = np.std(clean_df[col])\n",
    "        # Standard deviation of noise is the standard deviation of the column \n",
    "        random_deviates = np.random.normal(loc = 0, scale = std_dev, size = n_points)\n",
    "        \n",
    "        # Add the noise to the data frame\n",
    "        noise_df[col] = clean_df[col] + random_deviates\n",
    "        \n",
    "    # Return the noisy dataframe for predictions\n",
    "    return noise_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Generate noisy data (does not quite work yet)\n",
    "def generate_data(clean_df, sets = 10):\n",
    "    noise_predictions = []\n",
    "    for i in range(sets):\n",
    "        for season in ['spring', 'summer', 'fall', 'winter']:\n",
    "            noise_df = get_random_variants(clean_df)\n",
    "            _, _, _, predictions, _ = train_random_forest(df = noise_df, season = season, return_pred = True)\n",
    "            noise_predictions.append(predictions)\n",
    "    return noise_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculates the mean average percentage error between the true values and the predictions\n",
    "def mape(y_true, predictions):\n",
    "    y_true = np.array(y_true)\n",
    "    predictions = np.array(predictions)\n",
    "    # Find where y true is not equal to zero to avoid division by error infinities/errors\n",
    "    mean_diff = np.mean(np.where(y_true >0, np.divide(abs(y_true - predictions), y_true) * 100, 0))\n",
    "    return round(mean_diff, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Linear Model\n",
    "\n",
    "A linear model can work well for simple relationships. There are no hyperparameters to tune and the model trains and predicts quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Function that trains a linear model \n",
    "# Takes in a dataframe and season, optionally returns the predictions\n",
    "def train_linear_model(df, season = 'summer', return_pred = False):\n",
    "    \n",
    "    # Get the features and labels\n",
    "    X, y = get_features_labels(df, season = season)\n",
    "    \n",
    "    # Split into training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "    \n",
    "    # Create and train the model on the training data\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Find the performance metrics\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_test, predictions)), 6)\n",
    "    r_squared = round(model.score(X_test, y_test), 6)\n",
    "    mape_result = round(mape(y_test, predictions), 6)\n",
    "    \n",
    "    if return_pred:\n",
    "        return model, rmse, r_squared, mape_result, predictions, y_test\n",
    "    else:\n",
    "        return model, rmse, r_squared, mape_result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Random Forest\n",
    "\n",
    "The concept behind a random forest is straightforward: instead of using one decision tree (a capable machine learning model by itself) use many of them in order to reduce variance. A random forest is an ensemble model and can contain as many decisions trees as desired. There are a number of hyperparameters to tune, but for the moment, I will only change the number of decision trees in the forst to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Function takes in a datafame and season and trains a random forest model on the data\n",
    "def train_random_forest(df, season = 'summer', return_pred = False):\n",
    "    \n",
    "    # Get array of features and array of targets\n",
    "    X, y = get_features_labels(df = df, season = season)\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "    \n",
    "    # Create the model and fit on the training data, use 100 decision trees\n",
    "    model = RandomForestRegressor(n_estimators = 100, criterion = 'mse')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Find the performance metrics\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_test, predictions)), 6)\n",
    "    r_squared = round(model.score(X_test, y_test), 6)\n",
    "    mape_result = round(mape(y_test, predictions), 6)\n",
    "    \n",
    "    if return_pred:\n",
    "        return model, rmse, r_squared, mape_result, predictions, y_test\n",
    "    else:\n",
    "        return model, rmse, r_squared, mape_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "The next model to try is the support vector machine. This algorithm works by trying to minimize the margin separating the regresion line from the data points. It works on the principle that any relationship can be modeled as linear in high enough dimensions. A support vector machine uses a kernel to represent the data in higher dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function takes in a dataframe and season and trains then evaluates a support vector regressor \n",
    "def train_svr(df, season = 'summer', return_pred = False):\n",
    "    X, y = get_features_labels(df, season = season)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "    \n",
    "    # Create the support vector regressor\n",
    "    model = SVR(kernel = 'rbf')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Find the performance metrics\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_test, predictions)), 6)\n",
    "    r_squared = round(model.score(X_test, y_test), 6)\n",
    "    mape_result = round(mape(y_test, predictions), 6)\n",
    "    \n",
    "    if return_pred:\n",
    "        return model, rmse, r_squared, mape_result, predictions, y_test\n",
    "    else:\n",
    "        return model, rmse, r_squared, mape_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_pca_svr(df, season = \"summer\", return_pred = False, n_components = 10):\n",
    "    X, y = get_features_labels(df, season = season)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "    \n",
    "    # Perform PCA with the selected number of components\n",
    "    pca = PCA(n_components = n_components)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    \n",
    "    # Create the support vector regressor\n",
    "    model = SVR(kernel = 'rbf')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Find the performance metrics\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_test, predictions)), 6)\n",
    "    r_squared = round(model.score(X_test, y_test), 6)\n",
    "    mape_result = round(mape(y_test, predictions), 6)\n",
    "    \n",
    "    if return_pred:\n",
    "        return model, rmse, r_squared, mape_result, predictions, y_test\n",
    "    else:\n",
    "        return model, rmse, r_squared, mape_result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network\n",
    "\n",
    "A deep neural network (DNN) is capable of learning complex relationships with no feature engineering required. The deep neural network can be implemented with the Tensorflow library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to create and train a deep neural network for the dataframe in the given season\n",
    "# Using tensorflow to create a deep neural network and the layers library\n",
    "def train_dnn(df, season = 'summer', return_pred = False, neuron_list = [128, 256, 512, 1024, 512, 256, 128],\n",
    "              learning_rate = 0.01, keep_probability = 0.95, n_epochs = 1000, batch_size = 128):\n",
    "    \n",
    "    # Reset the graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Used for early stopping\n",
    "    max_checks_without_progress = 50\n",
    "    checks_without_progress = 0\n",
    "    \n",
    "    # Used for displaying results\n",
    "    check_freq = 10\n",
    "    \n",
    "    # Regression only has one class!\n",
    "    n_classes = 1\n",
    "    \n",
    "    # Get the features and labels as numpy arrays\n",
    "    features, labels = get_features_labels(df, season = season)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state = 42)\n",
    "    \n",
    "    # Number of training examples\n",
    "    n_training_examples = X_train.shape[0]\n",
    "    \n",
    "    # Number of inputs is the number of features\n",
    "    n_inputs = X_train.shape[1]\n",
    "    \n",
    "    \n",
    "    # Create placeholders for features, labels, and dropout\n",
    "    X = tf.placeholder(tf.float32, [None, n_inputs], name = \"X\")\n",
    "    y = tf.placeholder(tf.float32, [None], name = \"y\")\n",
    "    keep_fraction = tf.placeholder(tf.float32, name = \"keep\")\n",
    "    \n",
    "    # Initialization function, using he_init: https://arxiv.org/abs/1502.01852\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    \n",
    "    # Deep neural network, adapted for regression from https://github.com/ageron/handson-ml\n",
    "    # Using He Initialization, elu activation, and dropout\n",
    "    def dnn(inputs, keep_fraction, neuron_list = neuron_list , name = None,\n",
    "            activation = tf.nn.elu, initializer = he_init):\n",
    "        \n",
    "        # Create the neural network from the given list of neurons in each layer\n",
    "        with tf.variable_scope(name, \"dnn\"):\n",
    "            for index, layer_neurons in enumerate(neuron_list):\n",
    "                inputs = tf.layers.dense(inputs, layer_neurons, activation = activation,\n",
    "                                         kernel_initializer = initializer, \n",
    "                                         name = \"hidden%d\" % (index + 1))\n",
    "                \n",
    "                # Apply dropout\n",
    "                inputs = tf.nn.dropout(inputs, keep_prob = keep_fraction)\n",
    "                \n",
    "        # Final layer has only a single neuron\n",
    "        # bias_out = tf.Variable(tf.random_normal([n_classes], mean = 0, stddev = 0.01))\n",
    "        # weight_out = tf.Variable(tf.random_normal([neuron_list[-1], n_classes], mean = 0, stddev = 1/np.sqrt(neuron_list[-1])))\n",
    "        \n",
    "        # Final layer makes predictions using only one output neuron\n",
    "        # inputs = tf.add(tf.matmul(inputs, weight_out), bias_out)\n",
    "        outputs = tf.layers.dense(inputs, n_classes, activation = activation, \n",
    "                                 kernel_initializer = initializer,\n",
    "                                 name = \"outputs\")\n",
    "        \n",
    "        # Remove dimensions that are size 1\n",
    "        outputs = tf.squeeze(outputs)\n",
    "    \n",
    "        return outputs\n",
    "    \n",
    "    # Cost function is root mean squared\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        \n",
    "        # Use neural network to generate output\n",
    "        outputs = dnn(X, keep_fraction)\n",
    "        # Cost is root mean squared error\n",
    "        cost = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(y , outputs))), name = \"cost\")\n",
    "        \n",
    "    # Training is done with the Adam optimizer, learning rate can be tuned\n",
    "    with tf.name_scope(\"train\"):\n",
    "        # Algorithm to reduce cost is Adam optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(cost, name = \"training_op\")\n",
    "        \n",
    "    # Variable initializer and saver    \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Actual training must be done in a session\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Initialize variables, min cost starts out at infinity\n",
    "        sess.run(init)\n",
    "        min_cost = float('Inf')\n",
    "        \n",
    "        # Iterate for the given number of epochs\n",
    "        # Each epoch, the network is trained on ALL training examples\n",
    "        for epoch in range(n_epochs):\n",
    "            # Random indices\n",
    "            rnd_idxs = np.random.permutation(len(X_train))\n",
    "            # Random indices for the training examples\n",
    "            for rnd_indices in np.array_split(rnd_idxs, len(X_train) // batch_size):\n",
    "                X_batch, y_batch = X_train[rnd_indices], y_train[rnd_indices]\n",
    "                \n",
    "                # Train on the batch\n",
    "                sess.run([training_op], feed_dict = {X: X_batch, y: y_batch, keep_fraction: keep_probability})\n",
    "                \n",
    "            # Calculate training cost on a batch\n",
    "            training_cost = cost.eval(feed_dict = {X: X_batch, y: y_batch, keep_fraction: 1.0})\n",
    "            \n",
    "            # Print out the progress\n",
    "            # if epoch % check_freq == 0:\n",
    "                # print(\"Epoch: {}, training rmse: {:0.4f}\".format(epoch, training_cost))\n",
    "            \n",
    "            # If cost is lower than the minimum, save the model and results checks without progress\n",
    "            # Minimum cost is now that training cost\n",
    "            if training_cost < min_cost:\n",
    "                save_path = saver.save(sess, \"models/model_eval.ckpt\")\n",
    "                checks_without_progress = 0\n",
    "                min_cost = training_cost\n",
    "                \n",
    "            # If training cost is not lower than the lowest cost, increment the checks without progress\n",
    "            else:\n",
    "                checks_without_progress += 1\n",
    "                \n",
    "                # If the maximum checks without progress is reached, stop the training\n",
    "                if checks_without_progress > max_checks_without_progress:\n",
    "                    \n",
    "                    print(\"No progress made for {} epochs\".format(\n",
    "                        max_checks_without_progress))\n",
    "                    # Restore the best model, and make predictions on the test set\n",
    "                    saver.restore(sess, \"models/model_eval.ckpt\")\n",
    "                    \n",
    "                    # Evaluations\n",
    "                    test_rmse = cost.eval(feed_dict = {X: X_test, y: y_test, keep_fraction: 1.0})\n",
    "                    predictions = outputs.eval(feed_dict = {X: X_test, y: y_test, keep_fraction: 1.0})\n",
    "                    test_mape = mape(y_test, predictions)\n",
    "                    \n",
    "                    # Print out results and stop training\n",
    "                    print(\"Test rmse: {:0.4f}\".format(test_rmse))\n",
    "                    print(\"Test mape: {:0.6f}\".format(test_mape))\n",
    "                    \n",
    "                    break\n",
    "            \n",
    "    # Performance metric using sklearn\n",
    "    test_r_squared = r2_score(y_test, predictions)\n",
    "    \n",
    "    # Return the tensorflaw saver and performance metrics\n",
    "    return saver, test_rmse, test_r_squared, test_mape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training rmse: 1.7641\n",
      "Epoch: 10, training rmse: 1.9558\n",
      "Epoch: 20, training rmse: 1.8496\n",
      "Epoch: 30, training rmse: 1.3903\n",
      "Epoch: 40, training rmse: 3.9468\n",
      "Epoch: 50, training rmse: 4.0180\n",
      "INFO:tensorflow:Restoring parameters from models/aps_summer.ckpt\n",
      "Test rmse: 1.6338\n",
      "Test mape: 15.177246\n",
      "No progress made for 50 epochs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'r2_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-8108ca28938a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maps_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'python_data/f-APS_weather.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_rmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_r_squared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_mape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maps_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-107-06efbe94382a>\u001b[0m in \u001b[0;36mtrain_dnn\u001b[0;34m(df, season, return_pred, neuron_list, learning_rate, keep_probability, n_epochs, batch_size)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mtest_r_squared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtest_rmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_r_squared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_mape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r2_score' is not defined"
     ]
    }
   ],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()\n",
    "    \n",
    "aps_df = pd.read_csv('python_data/f-APS_weather.csv')\n",
    "saver, test_rmse, test_r_squared, test_mape = train_dnn(aps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features, labels = get_features_labels(aps_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a548d35be0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a54d2ea748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = list(range(len(predictions)))\n",
    "plt.scatter(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Model Evaluation\n",
    "\n",
    "Once all the models have been instantiated, it is necessary to test them to assess the accuracy. To test a model, \n",
    "the data is split into a training set and then a testing set the answers for which are withheld from the model. The model is trained on the training data (which includes the labels) and is then asked to make predictions on the test data. Whichever model performs the best on the test data will then be selected for optimization (hyperparameter tuning and feature engineering). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Function takes in a season and a model and runs all buildings through the model\n",
    "# Function returns a dataframe with comprehensive results\n",
    "def test_model(model_selection = 'random_forest', seasons = [\"spring\", \"summer\", \"fall\", \"winter\"]):\n",
    "    # Empty dataframe for results\n",
    "    results_df = pd.DataFrame()\n",
    "    \n",
    "    # Empty strings to append results to\n",
    "    season_names = []\n",
    "    buildings = []\n",
    "    rmses = []\n",
    "    r_squareds = []\n",
    "    mape_results = []\n",
    "\n",
    "    # Iterate through all files and make season predictions\n",
    "    for file in os.listdir('./python_data/'):\n",
    "        # Print file to gauge progress\n",
    "        print(file)\n",
    "        path = './python_data/' + file\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        # Building identifier\n",
    "        building = re.split('-|_', file)[1]\n",
    "        \n",
    "        for season in seasons:\n",
    "            # Use the model selected\n",
    "            if model_selection == 'random_forest':\n",
    "                model, rmse, r_squared, mape_result = train_random_forest(df, season = season)\n",
    "\n",
    "            elif model_selection == 'linear':\n",
    "                model, rmse, r_squared, mape_result = train_linear_model(df, season = season)\n",
    "\n",
    "            elif model_selection == 'svr':\n",
    "                model, rmse, r_squared, mape_result = train_svr(df, season = season)\n",
    "\n",
    "            elif model_selection == \"pca_svr\":\n",
    "                model, rmse, r_squared, mape_result = train_pca_svr(df, season = season, n_components = 10)\n",
    "            else:\n",
    "                print('Entire a valid model (\"random_forest\", \"linear\", \"svr\")')\n",
    "                return\n",
    "        \n",
    "    \n",
    "            # Add results to strings\n",
    "            season_names.append(season)\n",
    "            buildings.append(building)\n",
    "            rmses.append(rmse)\n",
    "            r_squareds.append(r_squared)\n",
    "            mape_results.append(mape_result)\n",
    "        \n",
    "    # Fill in dataframe of results\n",
    "    results_df['building'] = buildings\n",
    "    results_df['season'] = season_names\n",
    "    results_df['rmse'] = rmses\n",
    "    results_df['r_squared'] = r_squareds\n",
    "    results_df['mape (%)'] = mape_results\n",
    "    \n",
    "    \n",
    "    # Return comprehensive results\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-APS_weather.csv\n",
      "f-CoServ_weather.csv\n",
      "f-Kansas_weather.csv\n",
      "f-NVE_weather.csv\n",
      "f-PGE1_weather.csv\n",
      "f-SDGE_weather.csv\n",
      "f-SMUD_weather.csv\n",
      "f-SRP_weather.csv\n"
     ]
    }
   ],
   "source": [
    "pca_svr_srp = test_model(model_selection = \"pca_svr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building</th>\n",
       "      <th>season</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r_squared</th>\n",
       "      <th>mape (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APS</td>\n",
       "      <td>spring</td>\n",
       "      <td>1.415817</td>\n",
       "      <td>0.743649</td>\n",
       "      <td>17.688444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APS</td>\n",
       "      <td>summer</td>\n",
       "      <td>1.905991</td>\n",
       "      <td>0.753770</td>\n",
       "      <td>17.349742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APS</td>\n",
       "      <td>fall</td>\n",
       "      <td>1.966284</td>\n",
       "      <td>0.618709</td>\n",
       "      <td>20.381666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APS</td>\n",
       "      <td>winter</td>\n",
       "      <td>1.366203</td>\n",
       "      <td>0.499507</td>\n",
       "      <td>17.416810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CoServ</td>\n",
       "      <td>spring</td>\n",
       "      <td>0.086408</td>\n",
       "      <td>0.510416</td>\n",
       "      <td>47.030024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CoServ</td>\n",
       "      <td>summer</td>\n",
       "      <td>0.063972</td>\n",
       "      <td>0.671139</td>\n",
       "      <td>38.088296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CoServ</td>\n",
       "      <td>fall</td>\n",
       "      <td>0.078405</td>\n",
       "      <td>0.423489</td>\n",
       "      <td>49.181902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CoServ</td>\n",
       "      <td>winter</td>\n",
       "      <td>0.136244</td>\n",
       "      <td>0.497089</td>\n",
       "      <td>56.743886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>spring</td>\n",
       "      <td>1.146413</td>\n",
       "      <td>0.704198</td>\n",
       "      <td>18.280584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>summer</td>\n",
       "      <td>1.796629</td>\n",
       "      <td>0.732365</td>\n",
       "      <td>25.207834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>fall</td>\n",
       "      <td>1.555760</td>\n",
       "      <td>0.671864</td>\n",
       "      <td>16.523726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>winter</td>\n",
       "      <td>1.305600</td>\n",
       "      <td>0.578897</td>\n",
       "      <td>15.719384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NVE</td>\n",
       "      <td>spring</td>\n",
       "      <td>2.202448</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>31.122059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NVE</td>\n",
       "      <td>summer</td>\n",
       "      <td>3.069939</td>\n",
       "      <td>0.698751</td>\n",
       "      <td>26.981020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NVE</td>\n",
       "      <td>fall</td>\n",
       "      <td>2.822394</td>\n",
       "      <td>0.639784</td>\n",
       "      <td>32.687237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NVE</td>\n",
       "      <td>winter</td>\n",
       "      <td>1.937333</td>\n",
       "      <td>0.537535</td>\n",
       "      <td>32.228174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PGE1</td>\n",
       "      <td>spring</td>\n",
       "      <td>1.541763</td>\n",
       "      <td>0.643372</td>\n",
       "      <td>24.515523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PGE1</td>\n",
       "      <td>summer</td>\n",
       "      <td>1.013408</td>\n",
       "      <td>0.807773</td>\n",
       "      <td>27.415309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PGE1</td>\n",
       "      <td>fall</td>\n",
       "      <td>1.752400</td>\n",
       "      <td>0.487604</td>\n",
       "      <td>21.159782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PGE1</td>\n",
       "      <td>winter</td>\n",
       "      <td>1.932930</td>\n",
       "      <td>0.387731</td>\n",
       "      <td>21.117539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SDGE</td>\n",
       "      <td>spring</td>\n",
       "      <td>1.487522</td>\n",
       "      <td>0.834175</td>\n",
       "      <td>20.557293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SDGE</td>\n",
       "      <td>summer</td>\n",
       "      <td>1.603580</td>\n",
       "      <td>0.871687</td>\n",
       "      <td>19.792188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SDGE</td>\n",
       "      <td>fall</td>\n",
       "      <td>2.039556</td>\n",
       "      <td>0.763029</td>\n",
       "      <td>28.619955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SDGE</td>\n",
       "      <td>winter</td>\n",
       "      <td>2.018475</td>\n",
       "      <td>0.703449</td>\n",
       "      <td>25.721462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SMUD</td>\n",
       "      <td>spring</td>\n",
       "      <td>24.067484</td>\n",
       "      <td>0.776621</td>\n",
       "      <td>23.781595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SMUD</td>\n",
       "      <td>summer</td>\n",
       "      <td>30.139829</td>\n",
       "      <td>0.806602</td>\n",
       "      <td>26.033577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SMUD</td>\n",
       "      <td>fall</td>\n",
       "      <td>30.808591</td>\n",
       "      <td>0.717672</td>\n",
       "      <td>29.826648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SMUD</td>\n",
       "      <td>winter</td>\n",
       "      <td>25.423986</td>\n",
       "      <td>0.633066</td>\n",
       "      <td>29.266646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SRP</td>\n",
       "      <td>spring</td>\n",
       "      <td>5.134499</td>\n",
       "      <td>0.805576</td>\n",
       "      <td>8.933294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SRP</td>\n",
       "      <td>summer</td>\n",
       "      <td>5.655773</td>\n",
       "      <td>0.846394</td>\n",
       "      <td>9.606432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SRP</td>\n",
       "      <td>fall</td>\n",
       "      <td>5.371273</td>\n",
       "      <td>0.793635</td>\n",
       "      <td>9.867705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SRP</td>\n",
       "      <td>winter</td>\n",
       "      <td>6.444862</td>\n",
       "      <td>0.537872</td>\n",
       "      <td>13.331562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building  season       rmse  r_squared   mape (%)\n",
       "0       APS  spring   1.415817   0.743649  17.688444\n",
       "1       APS  summer   1.905991   0.753770  17.349742\n",
       "2       APS    fall   1.966284   0.618709  20.381666\n",
       "3       APS  winter   1.366203   0.499507  17.416810\n",
       "4    CoServ  spring   0.086408   0.510416  47.030024\n",
       "5    CoServ  summer   0.063972   0.671139  38.088296\n",
       "6    CoServ    fall   0.078405   0.423489  49.181902\n",
       "7    CoServ  winter   0.136244   0.497089  56.743886\n",
       "8    Kansas  spring   1.146413   0.704198  18.280584\n",
       "9    Kansas  summer   1.796629   0.732365  25.207834\n",
       "10   Kansas    fall   1.555760   0.671864  16.523726\n",
       "11   Kansas  winter   1.305600   0.578897  15.719384\n",
       "12      NVE  spring   2.202448   0.726045  31.122059\n",
       "13      NVE  summer   3.069939   0.698751  26.981020\n",
       "14      NVE    fall   2.822394   0.639784  32.687237\n",
       "15      NVE  winter   1.937333   0.537535  32.228174\n",
       "16     PGE1  spring   1.541763   0.643372  24.515523\n",
       "17     PGE1  summer   1.013408   0.807773  27.415309\n",
       "18     PGE1    fall   1.752400   0.487604  21.159782\n",
       "19     PGE1  winter   1.932930   0.387731  21.117539\n",
       "20     SDGE  spring   1.487522   0.834175  20.557293\n",
       "21     SDGE  summer   1.603580   0.871687  19.792188\n",
       "22     SDGE    fall   2.039556   0.763029  28.619955\n",
       "23     SDGE  winter   2.018475   0.703449  25.721462\n",
       "24     SMUD  spring  24.067484   0.776621  23.781595\n",
       "25     SMUD  summer  30.139829   0.806602  26.033577\n",
       "26     SMUD    fall  30.808591   0.717672  29.826648\n",
       "27     SMUD  winter  25.423986   0.633066  29.266646\n",
       "28      SRP  spring   5.134499   0.805576   8.933294\n",
       "29      SRP  summer   5.655773   0.846394   9.606432\n",
       "30      SRP    fall   5.371273   0.793635   9.867705\n",
       "31      SRP  winter   6.444862   0.537872  13.331562"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_svr_srp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "Of course, once all the models have been developed, they must be compared to one another. I will use the defaults for each algorithm and evaluate all the buildings across all the seasons. The best performing model will be selected for hyperparameter optimization. There are a number of parameters to select for the SVM and Random Forest, but at this point, I want to merely assess the baseline accuracy with the defaults. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes in a directory and compares all models across all seasons\n",
    "# Evaluation metrics: r_squared, rmse, and mape; models: linear regression, random forest ensemble, support vector regressor\n",
    "def compare_models(directory = 'python_data/'):\n",
    "    # Columns of results\n",
    "    column_names = ['building', 'season', 'linear_r_squared', 'linear_rmse', 'linear_mape', 'random_forest_r_squared', \n",
    "                    'random_forest_rmse', 'random_forest_mape', 'svr_r_squared', 'svr_rmse', 'svr_mape']\n",
    "    \n",
    "    seasons = ['spring', 'summer', 'fall', 'winter']\n",
    "    num_files = len(os.listdir(directory))\n",
    "    \n",
    "    n_rows = len(seasons) * num_files\n",
    "    \n",
    "    # Create dataframe with initially all zeros\n",
    "    complete_results = pd.DataFrame(data = np.zeros([n_rows, len(column_names)]), columns = column_names)\n",
    "    # Index for locating rows in dataframe\n",
    "    index = 0\n",
    "    \n",
    "    # Iterate through all seasons\n",
    "    for season in ['spring', 'summer', 'fall', 'winter']:\n",
    "        \n",
    "        # Iterate through all files in directory\n",
    "        for f in os.listdir(directory):\n",
    "            # Establish results list and add name and season\n",
    "            results = []\n",
    "            building_name = re.split('-|_', f)[1]\n",
    "            results.append(building_name)\n",
    "            results.append(season)\n",
    "            df = pd.read_csv(directory + f)\n",
    "            \n",
    "            # Linear Model\n",
    "            linear_model, linear_rmse, linear_r_squared, linear_mape_result = train_linear_model(df, season = season)\n",
    "            results.append(linear_r_squared)\n",
    "            results.append(linear_rmse)  \n",
    "            results.append(linear_mape_result)\n",
    "                        \n",
    "            # Random Forest\n",
    "            rf_model, rf_rmse, rf_r_squared, rf_mape_result = train_random_forest(df, season = season)\n",
    "            results.append(rf_r_squared)\n",
    "            results.append(rf_rmse)\n",
    "            results.append(rf_mape_result)\n",
    "            \n",
    "            # SVR\n",
    "            svr_model, svr_rmse, svr_r_squared, svr_mape_result = train_svr(df, season = season)\n",
    "            results.append(svr_r_squared)\n",
    "            results.append(svr_rmse)\n",
    "            results.append(svr_mape_result)\n",
    "            \n",
    "            # Deep Neural Network\n",
    "            # dnn_saver, dnn_rmse, dnn_r_squared, dnn_mape_result = train_dnn(df, season = season)\n",
    "            # results.append(dnn_r_squared)\n",
    "            # results.append(dnn_rmse)\n",
    "            # results.append(dnn_mape_result)\n",
    "            \n",
    "            # Add the results to the dataframe at the next row\n",
    "            complete_results.iloc[index, :] = results\n",
    "            \n",
    "            # Increase the index by one\n",
    "            index = index + 1\n",
    "            \n",
    "        print(season)\n",
    "    return complete_results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spring\n",
      "summer\n",
      "fall\n",
      "winter\n"
     ]
    }
   ],
   "source": [
    "complete_test_results = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'results.feather'\n",
    "feather.write_dataframe(complete_test_results, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_test_results = complete_test_results[complete_test_results['building'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model average MAPE: 39.1466\n",
      "Random Forest average MAPE 7.1169\n",
      "SVR with RBF average MAPE  26.6159\n"
     ]
    }
   ],
   "source": [
    "print('Linear Model average MAPE: {:0.4f}'.format(np.mean(full_test_results['linear_mape'])))\n",
    "print('Random Forest average MAPE {:0.4f}'.format(np.mean(full_test_results['random_forest_mape'])))\n",
    "print('SVR with RBF average MAPE  {:0.4f}'.format(np.mean(full_test_results['svr_mape'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparamter Tuning\n",
    "\n",
    "The Random Forest performs best by far on the test data. The next step is to optimize the hyperparameters for the model. I was using the default hyperparameters for the Random Forest in sklearn with 100 estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_parameters = {\n",
    "    'n_estimators': [int(x) for x in list(np.linspace(10, 200, num = 10))],\n",
    "    'max_features': ['auto', 0.5, 0.8],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 4, 8]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "random_search = RandomizedSearchCV(rf_model, rf_parameters, n_iter = 50, \n",
    "                                   verbose = 2, scoring = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] n_estimators=200, min_samples_split=2, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=2, max_features=auto, max_depth=None, total=  17.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=200, min_samples_split=2, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=2, max_features=auto, max_depth=None, total=18.0min\n",
      "[CV] n_estimators=200, min_samples_split=2, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=2, max_features=auto, max_depth=None, total=77.0min\n",
      "[CV] n_estimators=178, min_samples_split=4, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=4, max_features=0.8, max_depth=None, total=   9.0s\n",
      "[CV] n_estimators=178, min_samples_split=4, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=4, max_features=0.8, max_depth=None, total=   9.4s\n",
      "[CV] n_estimators=178, min_samples_split=4, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=4, max_features=0.8, max_depth=None, total=   9.3s\n",
      "[CV] n_estimators=31, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=31, min_samples_split=8, max_features=0.5, max_depth=None, total=   1.0s\n",
      "[CV] n_estimators=31, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=31, min_samples_split=8, max_features=0.5, max_depth=None, total=   1.1s\n",
      "[CV] n_estimators=31, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=31, min_samples_split=8, max_features=0.5, max_depth=None, total=   1.0s\n",
      "[CV] n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=None, total=   9.0s\n",
      "[CV] n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=None, total=  11.0s\n",
      "[CV] n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=None, total=   8.1s\n",
      "[CV] n_estimators=136, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=136, min_samples_split=2, max_features=0.8, max_depth=10, total=  11.3s\n",
      "[CV] n_estimators=136, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=136, min_samples_split=2, max_features=0.8, max_depth=10, total=   6.6s\n",
      "[CV] n_estimators=136, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=136, min_samples_split=2, max_features=0.8, max_depth=10, total=   6.4s\n",
      "[CV] n_estimators=157, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=157, min_samples_split=4, max_features=0.8, max_depth=10, total=   8.9s\n",
      "[CV] n_estimators=157, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=157, min_samples_split=4, max_features=0.8, max_depth=10, total=   8.5s\n",
      "[CV] n_estimators=157, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=157, min_samples_split=4, max_features=0.8, max_depth=10, total=   6.5s\n",
      "[CV] n_estimators=73, min_samples_split=2, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=73, min_samples_split=2, max_features=0.8, max_depth=None, total=   4.6s\n",
      "[CV] n_estimators=73, min_samples_split=2, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=73, min_samples_split=2, max_features=0.8, max_depth=None, total=   4.6s\n",
      "[CV] n_estimators=73, min_samples_split=2, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=73, min_samples_split=2, max_features=0.8, max_depth=None, total=   4.5s\n",
      "[CV] n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=10, total=   5.0s\n",
      "[CV] n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=10, total=   4.9s\n",
      "[CV] n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=10, total=   4.7s\n",
      "[CV] n_estimators=94, min_samples_split=8, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=94, min_samples_split=8, max_features=0.8, max_depth=10, total=   4.5s\n",
      "[CV] n_estimators=94, min_samples_split=8, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=94, min_samples_split=8, max_features=0.8, max_depth=10, total=   4.5s\n",
      "[CV] n_estimators=94, min_samples_split=8, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=94, min_samples_split=8, max_features=0.8, max_depth=10, total=   5.7s\n",
      "[CV] n_estimators=115, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=115, min_samples_split=4, max_features=0.5, max_depth=None, total=   6.1s\n",
      "[CV] n_estimators=115, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=115, min_samples_split=4, max_features=0.5, max_depth=None, total=   5.6s\n",
      "[CV] n_estimators=115, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=115, min_samples_split=4, max_features=0.5, max_depth=None, total=   4.7s\n",
      "[CV] n_estimators=73, min_samples_split=8, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=73, min_samples_split=8, max_features=0.8, max_depth=None, total=   8.9s\n",
      "[CV] n_estimators=73, min_samples_split=8, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=73, min_samples_split=8, max_features=0.8, max_depth=None, total=   4.6s\n",
      "[CV] n_estimators=73, min_samples_split=8, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=73, min_samples_split=8, max_features=0.8, max_depth=None, total=   4.0s\n",
      "[CV] n_estimators=136, min_samples_split=8, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=8, max_features=0.8, max_depth=None, total=   7.3s\n",
      "[CV] n_estimators=136, min_samples_split=8, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=8, max_features=0.8, max_depth=None, total=   8.0s\n",
      "[CV] n_estimators=136, min_samples_split=8, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=8, max_features=0.8, max_depth=None, total=   7.3s\n",
      "[CV] n_estimators=178, min_samples_split=8, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=178, min_samples_split=8, max_features=auto, max_depth=10, total=  11.9s\n",
      "[CV] n_estimators=178, min_samples_split=8, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=178, min_samples_split=8, max_features=auto, max_depth=10, total=   9.1s\n",
      "[CV] n_estimators=178, min_samples_split=8, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=178, min_samples_split=8, max_features=auto, max_depth=10, total=   8.8s\n",
      "[CV] n_estimators=157, min_samples_split=8, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=157, min_samples_split=8, max_features=auto, max_depth=None, total=  11.8s\n",
      "[CV] n_estimators=157, min_samples_split=8, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=157, min_samples_split=8, max_features=auto, max_depth=None, total=  11.6s\n",
      "[CV] n_estimators=157, min_samples_split=8, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=157, min_samples_split=8, max_features=auto, max_depth=None, total=  11.5s\n",
      "[CV] n_estimators=31, min_samples_split=4, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=31, min_samples_split=4, max_features=0.8, max_depth=None, total=   1.8s\n",
      "[CV] n_estimators=31, min_samples_split=4, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=31, min_samples_split=4, max_features=0.8, max_depth=None, total=   1.8s\n",
      "[CV] n_estimators=31, min_samples_split=4, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=31, min_samples_split=4, max_features=0.8, max_depth=None, total=   1.8s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=auto, max_depth=None, total=  14.8s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=auto, max_depth=None, total=  14.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=auto, max_depth=None, total=  14.8s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=None, total=  12.6s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=None, total=  12.7s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=None, total=  12.8s\n",
      "[CV] n_estimators=52, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=52, min_samples_split=8, max_features=0.5, max_depth=None, total=   1.8s\n",
      "[CV] n_estimators=52, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=52, min_samples_split=8, max_features=0.5, max_depth=None, total=   1.8s\n",
      "[CV] n_estimators=52, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=52, min_samples_split=8, max_features=0.5, max_depth=None, total=   1.8s\n",
      "[CV] n_estimators=52, min_samples_split=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=52, min_samples_split=4, max_features=auto, max_depth=10, total=   2.5s\n",
      "[CV] n_estimators=52, min_samples_split=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=52, min_samples_split=4, max_features=auto, max_depth=10, total=   2.5s\n",
      "[CV] n_estimators=52, min_samples_split=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=52, min_samples_split=4, max_features=auto, max_depth=10, total=   2.5s\n",
      "[CV] n_estimators=52, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=52, min_samples_split=4, max_features=0.8, max_depth=10, total=   2.1s\n",
      "[CV] n_estimators=52, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=52, min_samples_split=4, max_features=0.8, max_depth=10, total=   2.1s\n",
      "[CV] n_estimators=52, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=52, min_samples_split=4, max_features=0.8, max_depth=10, total=   2.0s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=10, total=   5.4s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=10, total=   5.4s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=10, total=   5.5s\n",
      "[CV] n_estimators=31, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=31, min_samples_split=2, max_features=0.8, max_depth=10, total=   1.2s\n",
      "[CV] n_estimators=31, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=31, min_samples_split=2, max_features=0.8, max_depth=10, total=   1.2s\n",
      "[CV] n_estimators=31, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=31, min_samples_split=2, max_features=0.8, max_depth=10, total=   1.2s\n",
      "[CV] n_estimators=115, min_samples_split=8, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=115, min_samples_split=8, max_features=auto, max_depth=10, total=   5.6s\n",
      "[CV] n_estimators=115, min_samples_split=8, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=115, min_samples_split=8, max_features=auto, max_depth=10, total=   5.6s\n",
      "[CV] n_estimators=115, min_samples_split=8, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=115, min_samples_split=8, max_features=auto, max_depth=10, total=   5.5s\n",
      "[CV] n_estimators=178, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=2, max_features=0.5, max_depth=None, total=   8.2s\n",
      "[CV] n_estimators=178, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=2, max_features=0.5, max_depth=None, total=   8.1s\n",
      "[CV] n_estimators=178, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=2, max_features=0.5, max_depth=None, total=   8.2s\n",
      "[CV] n_estimators=31, min_samples_split=8, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=31, min_samples_split=8, max_features=auto, max_depth=None, total=   1.9s\n",
      "[CV] n_estimators=31, min_samples_split=8, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=31, min_samples_split=8, max_features=auto, max_depth=None, total=   1.9s\n",
      "[CV] n_estimators=31, min_samples_split=8, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=31, min_samples_split=8, max_features=auto, max_depth=None, total=   1.9s\n",
      "[CV] n_estimators=73, min_samples_split=8, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=73, min_samples_split=8, max_features=auto, max_depth=10, total=   3.5s\n",
      "[CV] n_estimators=73, min_samples_split=8, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=73, min_samples_split=8, max_features=auto, max_depth=10, total=   3.7s\n",
      "[CV] n_estimators=73, min_samples_split=8, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=73, min_samples_split=8, max_features=auto, max_depth=10, total=   3.6s\n",
      "[CV] n_estimators=178, min_samples_split=8, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=8, max_features=0.8, max_depth=None, total=   9.5s\n",
      "[CV] n_estimators=178, min_samples_split=8, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=8, max_features=0.8, max_depth=None, total=   9.5s\n",
      "[CV] n_estimators=178, min_samples_split=8, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=8, max_features=0.8, max_depth=None, total=   9.7s\n",
      "[CV] n_estimators=115, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=115, min_samples_split=4, max_features=0.8, max_depth=10, total=   4.6s\n",
      "[CV] n_estimators=115, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=115, min_samples_split=4, max_features=0.8, max_depth=10, total=   4.6s\n",
      "[CV] n_estimators=115, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=115, min_samples_split=4, max_features=0.8, max_depth=10, total=   4.6s\n",
      "[CV] n_estimators=115, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=115, min_samples_split=8, max_features=0.5, max_depth=None, total=   4.1s\n",
      "[CV] n_estimators=115, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=115, min_samples_split=8, max_features=0.5, max_depth=None, total=   4.1s\n",
      "[CV] n_estimators=115, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=115, min_samples_split=8, max_features=0.5, max_depth=None, total=   4.1s\n",
      "[CV] n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=None, total=   5.4s\n",
      "[CV] n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=None, total=   5.5s\n",
      "[CV] n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=4, max_features=0.5, max_depth=None, total=   5.5s\n",
      "[CV] n_estimators=136, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=2, max_features=0.5, max_depth=None, total=   6.1s\n",
      "[CV] n_estimators=136, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=2, max_features=0.5, max_depth=None, total=   6.2s\n",
      "[CV] n_estimators=136, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=2, max_features=0.5, max_depth=None, total=   6.3s\n",
      "[CV] n_estimators=52, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=52, min_samples_split=2, max_features=0.5, max_depth=None, total=   2.3s\n",
      "[CV] n_estimators=52, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=52, min_samples_split=2, max_features=0.5, max_depth=None, total=   2.3s\n",
      "[CV] n_estimators=52, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=52, min_samples_split=2, max_features=0.5, max_depth=None, total=   2.3s\n",
      "[CV] n_estimators=94, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=94, min_samples_split=2, max_features=0.5, max_depth=None, total=   4.3s\n",
      "[CV] n_estimators=94, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=94, min_samples_split=2, max_features=0.5, max_depth=None, total=   4.3s\n",
      "[CV] n_estimators=94, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=94, min_samples_split=2, max_features=0.5, max_depth=None, total=   4.3s\n",
      "[CV] n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=10, total=   4.7s\n",
      "[CV] n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=10, total=   4.6s\n",
      "[CV] n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=115, min_samples_split=2, max_features=0.8, max_depth=10, total=   4.7s\n",
      "[CV] n_estimators=94, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=94, min_samples_split=4, max_features=0.8, max_depth=10, total=   3.7s\n",
      "[CV] n_estimators=94, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=94, min_samples_split=4, max_features=0.8, max_depth=10, total=   3.7s\n",
      "[CV] n_estimators=94, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=94, min_samples_split=4, max_features=0.8, max_depth=10, total=   3.7s\n",
      "[CV] n_estimators=178, min_samples_split=2, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=2, max_features=auto, max_depth=None, total=  14.5s\n",
      "[CV] n_estimators=178, min_samples_split=2, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=2, max_features=auto, max_depth=None, total=  14.4s\n",
      "[CV] n_estimators=178, min_samples_split=2, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=2, max_features=auto, max_depth=None, total=  14.5s\n",
      "[CV] n_estimators=157, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=157, min_samples_split=2, max_features=0.8, max_depth=10, total=   6.5s\n",
      "[CV] n_estimators=157, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=157, min_samples_split=2, max_features=0.8, max_depth=10, total=   6.3s\n",
      "[CV] n_estimators=157, min_samples_split=2, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=157, min_samples_split=2, max_features=0.8, max_depth=10, total=   6.3s\n",
      "[CV] n_estimators=200, min_samples_split=8, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=8, max_features=auto, max_depth=None, total=  13.6s\n",
      "[CV] n_estimators=200, min_samples_split=8, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=8, max_features=auto, max_depth=None, total=  14.0s\n",
      "[CV] n_estimators=200, min_samples_split=8, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=8, max_features=auto, max_depth=None, total=  13.6s\n",
      "[CV] n_estimators=200, min_samples_split=8, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=8, max_features=0.5, max_depth=10, total=   5.3s\n",
      "[CV] n_estimators=200, min_samples_split=8, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=8, max_features=0.5, max_depth=10, total=   5.3s\n",
      "[CV] n_estimators=200, min_samples_split=8, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=8, max_features=0.5, max_depth=10, total=   5.4s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=None, total=   8.1s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=None, total=   8.1s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.5, max_depth=None, total=   8.2s\n",
      "[CV] n_estimators=52, min_samples_split=8, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=52, min_samples_split=8, max_features=0.8, max_depth=10, total=   2.0s\n",
      "[CV] n_estimators=52, min_samples_split=8, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=52, min_samples_split=8, max_features=0.8, max_depth=10, total=   2.0s\n",
      "[CV] n_estimators=52, min_samples_split=8, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=52, min_samples_split=8, max_features=0.8, max_depth=10, total=   2.0s\n",
      "[CV] n_estimators=52, min_samples_split=4, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=52, min_samples_split=4, max_features=auto, max_depth=None, total=   3.7s\n",
      "[CV] n_estimators=52, min_samples_split=4, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=52, min_samples_split=4, max_features=auto, max_depth=None, total=   3.7s\n",
      "[CV] n_estimators=52, min_samples_split=4, max_features=auto, max_depth=None \n",
      "[CV]  n_estimators=52, min_samples_split=4, max_features=auto, max_depth=None, total=   3.8s\n",
      "[CV] n_estimators=178, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=4, max_features=0.5, max_depth=None, total=   7.2s\n",
      "[CV] n_estimators=178, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=4, max_features=0.5, max_depth=None, total=   7.2s\n",
      "[CV] n_estimators=178, min_samples_split=4, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=178, min_samples_split=4, max_features=0.5, max_depth=None, total=   7.2s\n",
      "[CV] n_estimators=10, min_samples_split=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, max_features=auto, max_depth=10, total=   0.4s\n",
      "[CV] n_estimators=10, min_samples_split=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, max_features=auto, max_depth=10, total=   0.4s\n",
      "[CV] n_estimators=10, min_samples_split=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, max_features=auto, max_depth=10, total=   0.4s\n",
      "[CV] n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=136, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=8, max_features=0.5, max_depth=None, total=   4.9s\n",
      "[CV] n_estimators=136, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=8, max_features=0.5, max_depth=None, total=   4.8s\n",
      "[CV] n_estimators=136, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=136, min_samples_split=8, max_features=0.5, max_depth=None, total=   5.0s\n",
      "[CV] n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=2, max_features=0.5, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=10, total=   8.0s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=10, total=   8.0s\n",
      "[CV] n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, max_features=0.8, max_depth=10, total=   8.0s\n",
      "[CV] n_estimators=10, min_samples_split=2, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=10, min_samples_split=2, max_features=0.8, max_depth=None, total=   0.6s\n",
      "[CV] n_estimators=10, min_samples_split=2, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=10, min_samples_split=2, max_features=0.8, max_depth=None, total=   0.6s\n",
      "[CV] n_estimators=10, min_samples_split=2, max_features=0.8, max_depth=None \n",
      "[CV]  n_estimators=10, min_samples_split=2, max_features=0.8, max_depth=None, total=   0.6s\n",
      "[CV] n_estimators=157, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=157, min_samples_split=8, max_features=0.5, max_depth=None, total=   5.6s\n",
      "[CV] n_estimators=157, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=157, min_samples_split=8, max_features=0.5, max_depth=None, total=   5.6s\n",
      "[CV] n_estimators=157, min_samples_split=8, max_features=0.5, max_depth=None \n",
      "[CV]  n_estimators=157, min_samples_split=8, max_features=0.5, max_depth=None, total=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 110.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=50, n_jobs=1,\n",
       "          param_distributions={'n_estimators': [10, 31, 52, 73, 94, 115, 136, 157, 178, 200], 'max_features': ['auto', 0.5, 0.8], 'max_depth': [None, 10], 'min_samples_split': [2, 4, 8]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srp_summer_df = pd.read_csv('python_data/f-SRP_weather.csv')\n",
    "X, y = get_features_labels(srp_summer_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8795419999999998"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = random_search.predict(X_test)\n",
    "mape(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smud_summer_df = pd.read_csv('python_data/f-SMUD_weather.csv')\n",
    "X, y = get_features_labels(smud_summer_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "random_search_smud = RandomizedSearchCV(rf_model, rf_parameters, n_jobs=-1, n_iter = 100, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 17.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mape: 8.120253\n"
     ]
    }
   ],
   "source": [
    "random_search_smud.fit(X_train, y_train)\n",
    "predictions = random_search_smud.predict(X_test)\n",
    "print(\"test mape: {:0.6f}\".format(mape(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=0.5, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_smud\n",
    "random_search_smud.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 6)\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "\n",
    "def plot_building(df, season = 'summer'):\n",
    "    # Reuslts of training and prediction\n",
    "    model, rmse, r_squared, mape_result, predictions, y_test = train_random_forest(df, season, return_pred = True)\n",
    "    \n",
    "    print('rmse: {:0.4f} mape: {:0.4f} r_squared: {:0.4f}'.format(rmse, mape_result, r_squared))\n",
    "    \n",
    "    plt.scatter(predictions, y_test);\n",
    "    plt.ylabel('True Value (kWh)');\n",
    "    plt.xlabel('Prediction Value (kWh)');\n",
    "    plt.title('{} True vs. Predicted Value with Random Forest Model'.format(season));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "aps_df = pd.read_csv('./data/f-APS_weather.csv')\n",
    "plot_building(aps_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Feature Importances \n",
    "\n",
    "\n",
    "The random forest model is able to return the feature importances which can be useful for determining which variables are most closely tied to energy consumption. These are relative and not absolute, but can be used for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def building_feature_importances(df, season = 'summer'):\n",
    "    print('{:20} Importance\\n'.format('Variable'))\n",
    "    model, rmse, r_squared, mape_result = train_random_forest(df, season)\n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_importances = sorted(feature_importances, key = lambda x: x, reverse = True)\n",
    "    col_names = get_features_labels(df, names = True)\n",
    "    for col_name, importance in zip(col_names, feature_importances):\n",
    "        print('{:20} {:0.5f}'.format(col_name, importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable             Importance\n",
      "\n",
      "num_time             0.17037\n",
      "ghi                  0.16755\n",
      "dif                  0.13057\n",
      "gti                  0.11836\n",
      "temp                 0.09185\n",
      "rh                   0.07071\n",
      "pwat                 0.06382\n",
      "ws                   0.05114\n",
      "month                0.03118\n",
      "day                  0.01789\n",
      "season_day           0.01629\n",
      "sun_rise_set_rise    0.01619\n",
      "sun_rise_set_set     0.01413\n",
      "biz_day_0            0.01168\n",
      "biz_day_1            0.01144\n",
      "day_of_week_Fri      0.00670\n",
      "day_of_week_Mon      0.00362\n",
      "day_of_week_Sat      0.00165\n",
      "day_of_week_Sun      0.00117\n",
      "day_of_week_Thu      0.00099\n",
      "day_of_week_Tue      0.00091\n",
      "day_of_week_Wed      0.00087\n",
      "week_day_end_day     0.00082\n",
      "week_day_end_end     0.00008\n"
     ]
    }
   ],
   "source": [
    "aps_df = pd.read_csv('python_data/f-APS_weather.csv')\n",
    "building_feature_importances(aps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def complete_model(filepath, plot = False):\n",
    "    building_name = re.split('-|_', filepath)[1]\n",
    "    results_dict = {}\n",
    "    df = pd.read_csv(filepath)\n",
    "    for index, season in enumerate(['spring', 'summer', 'fall', 'winter']):\n",
    "        model, rmse, r_squared, mape, predictions, y_true = train_random_forest(df, season = season, return_pred = True)\n",
    "        results_dict[season] = {'model': model, 'rmse': rmse, 'r_squared': r_squared}\n",
    "        colors = [\"green\", \"red\", \"orange\", \"blue\"]\n",
    "        if plot:\n",
    "            plt.figure(figsize = (10, 20))\n",
    "            plt.subplot(4, 1, index + 1)\n",
    "            plt.scatter(predictions, y_true, color = colors[index])\n",
    "            plt.ylabel('True Value of Electricity Consumption');\n",
    "            plt.xlabel('Prediction Value of Electricity Consumption');\n",
    "            plt.title('%s %s True vs. Predicted Energy with Random Forest Model'% (building_name, season));\n",
    "            print('R-Squared: {:0.4f} rmse: {:0.4f}'.format(r_squared, rmse))\n",
    "            plt.show()\n",
    "            \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "kansas_results = complete_model('./data/f-Kansas_weather.csv', plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "aps_df = pd.read_csv('./data/f-APS_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def predict_mid(df):\n",
    "    results_df = pd.DataFrame()\n",
    "    results_df['forecast'] = df['forecast']\n",
    "    results_df['timestamp'] = df['timestamp']\n",
    "    \n",
    "    # Predicts middle 25% of data for each season\n",
    "    for index, season in enumerate([\"spring\", \"summer\", \"fall\", \"winter\"]):\n",
    "        \n",
    "        X, y, season_dates, names = get_features_labels(df, season = season, return_dates = True, names = True)\n",
    "        month_index = names.index('month')\n",
    "        \n",
    "        # Take middle 25% of data for testing\n",
    "        start_index = round(0.375 * y.shape[0])\n",
    "        stop_index = round(0.625 * y.shape[0])\n",
    "\n",
    "        # Join arrays together adding rows\n",
    "        X_train_beginning = X[0:start_index]\n",
    "        X_train_end = X[stop_index:]\n",
    "        X_train = np.concatenate((X_train_beginning, X_train_end), axis = 0)\n",
    "        X_test = X[start_index: stop_index]\n",
    "        \n",
    "        # Do same with features\n",
    "        y_train_beginning = y[0:start_index]\n",
    "        y_train_end = y[stop_index:]\n",
    "        y_train = np.concatenate((y_train_beginning, y_train_end), axis = 0)\n",
    "        y_test = y[start_index:stop_index]\n",
    "        \n",
    "        model = RandomForestRegressor(n_estimators = 100, criterion = 'mse')\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        predictions_df = pd.DataFrame()\n",
    "        predictions_df['timestamp'] = season_dates[start_index:stop_index]\n",
    "        predictions_df[season] = predictions\n",
    "        \n",
    "        results_df = pd.merge(results_df, predictions_df, how = 'outer', on = 'timestamp')\n",
    "        results_df[season] = np.nan_to_num(results_df[season])\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        \n",
    "        print('Season {}; RMSE on test data: {:0.4f}'.format(season, rmse))\n",
    "        \n",
    "        x_values = range(0, len(y_train) + len(y_test))\n",
    "        \n",
    "        if season.lower() == \"spring\":\n",
    "            spring_df = pd.DataFrame()\n",
    "            spring_df['timestamp'] = [parser.parse(date) for date in season_dates[start_index:stop_index]]\n",
    "            spring_df['predictions'] = predictions\n",
    "            datetimes = pd.date_range('2016-03-01 00:00:00', periods = len(x_values), freq = '0.25H').tolist()\n",
    "        elif season.lower() == \"summer\":\n",
    "            summer_df = pd.DataFrame()\n",
    "            summer_df['timestamp'] = [parser.parse(date) for date in season_dates[start_index:stop_index]]\n",
    "            summer_df['predictions'] = predictions\n",
    "            datetimes = pd.date_range('2016-06-01 00:00:00', periods = len(x_values), freq = '0.25H').tolist()\n",
    "        elif season.lower() == \"fall\":\n",
    "            fall_df = pd.DataFrame()\n",
    "            fall_df['timestamp'] = [parser.parse(date) for date in season_dates[start_index:stop_index]]\n",
    "            fall_df['predictions'] = predictions\n",
    "            datetimes = pd.date_range('2016-08-01 00:00:00', periods = len(x_values), freq = '0.25H').tolist()\n",
    "        elif season.lower() == \"winter\":\n",
    "            winter_df = pd.DataFrame()\n",
    "            winter_df['timestamp'] = [parser.parse(date) for date in season_dates[start_index:stop_index]]\n",
    "            winter_df['predictions'] = predictions\n",
    "            datetimes = pd.date_range('2016-12-01 00:00:00', periods = len(x_values) , freq = '0.25H').tolist()\n",
    "        \n",
    "        datetimes_test = datetimes[start_index:stop_index]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize = (15, 6))\n",
    "        \n",
    "        datemin = datetimes[0]\n",
    "        datemax = datetimes[-1]\n",
    "        \n",
    "        ax.plot(datetimes, y, color = \"black\")\n",
    "        ax.plot(datetimes_test, predictions, color = \"red\")\n",
    "        \n",
    "        yearsFmt = mdates.DateFormatter('%Y-%m')\n",
    "        ax.xaxis.set_major_formatter(yearsFmt)\n",
    "        ax.set_xlim(datemin, datemax)\n",
    "        fig.autofmt_xdate()\n",
    "        \n",
    "        plt.legend(['Actual', 'Predicted'])\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('kWh')\n",
    "        plt.title('{} Predicted vs. Actual Energy Consumption'.format(season))\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (15, 10))\n",
    "    dt = [parser.parse(date) for date in results_df['timestamp']]\n",
    "    datemin = dt[0]\n",
    "    datemax = dt[-1]\n",
    "    \n",
    "    ax.plot(dt, results_df['forecast'], color = 'black')\n",
    "    ax.plot(summer_df['timestamp'], summer_df['predictions'], color = 'yellow')\n",
    "    ax.plot(fall_df['timestamp'], fall_df['predictions'], color = 'orange')\n",
    "    ax.plot(winter_df['timestamp'], winter_df['predictions'], color = 'blue')\n",
    "    ax.plot(spring_df['timestamp'], spring_df['predictions'], color = 'green')\n",
    "    \n",
    "    yearsFmt = mdates.DateFormatter('%Y-%m')\n",
    "    ax.xaxis.set_major_formatter(yearsFmt)\n",
    "    ax.set_xlim(datemin, datemax)\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    plt.legend(['Actual', 'Predicted Summer', 'Predicted Fall', 'Predicted Winter', 'Predicted Fall'])\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('kWh')\n",
    "    plt.title('Predicted vs. Actual Energy Consumption')\n",
    "    plt.show()\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = predict_mid(aps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "smud_df = pd.read_csv('./data/f-SMUD_weather.csv')\n",
    "results_smud = predict_mid(smud_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# TPOT: Autonomous Model Evaluation\n",
    "\n",
    "TPOT is a library that automatically runs a machine learning dataset through a number of different models to find the one best suited to the data. It can be used to find the best model for a particular dataset or problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "aps_df = pd.read_csv('./python_data/f-APS_weather.csv')\n",
    "X, y = get_features_labels(aps_df, season = 'summer')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "tpot_aps = TPOTRegressor(generations = 10, population_size = 10, cv = 2, max_eval_time_mins = 2, verbosity = 2)\n",
    "tpot_aps.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tpot_aps.export('./tpot_pipelines/aps_summer_pipe.py')\n",
    "tpot_aps.fitted_pipeline_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mape(y_test, tpot_aps.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tpot_aps.evaluated_individuals_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aps_df = pd.read_csv('./python_data/f-APS_weather.csv')\n",
    "X, y = get_features_labels(aps_df, season = 'summer')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "tpot_aps_2 = TPOTRegressor(generations = 10, population_size = 10, cv = 2, max_eval_time_mins = 2, verbosity = 2)\n",
    "tpot_aps_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tpot_aps_2.export('./tpot_pipelines/aps_summer_pipe.py')\n",
    "tpot_aps_2.fitted_pipeline_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = tpot_aps_2.predict(X_test)\n",
    "print('Mean absolute percentage error: {}'.format(mape(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization\n",
    "\n",
    "A Random Forest is composed of many individual decision trees (100) in this case. Each decision tree has its own thresholds for regression, and it is possible to visualize these decision trees using graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "srp_df = pd.read_csv('./python_data/f-SRP_weather.csv')\n",
    "X, y, column_names = get_features_labels(srp_df, season = 'summer', names = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "rf_model = RandomForestRegressor(n_estimators = 100, n_jobs = -1)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_graphviz(rf_model.estimators_[42],\n",
    "                feature_names =  column_names,\n",
    "                filled = True,\n",
    "                rounded = True)\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)\n",
    "\n",
    "import pydot\n",
    "\n",
    "(graph,) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('srp_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
