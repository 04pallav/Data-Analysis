{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Cross-Sectional Building EDA\"\nauthor: \"William Koehrsen\"\ndate: \"December 6, 2017\"\noutput:\n  html_document:\n    theme: sandstone\n    number_sections: yes\n    toc: yes\n    toc_float: yes\n  pdf_document:\n    number_sections: yes\n    toc: yes\n---\n\n![](map.gif)\n\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nknitr::opts_chunk$set(cache = TRUE)\nknitr::opts_chunk$set(echo = FALSE)\nknitr::opts_chunk$set(message = FALSE)\nknitr::opts_chunk$set(warning = FALSE)\n\nlibrary(lubridate)\nlibrary(data.table)\nlibrary(ggthemes)\nlibrary(ggmap)\nlibrary(feather)\nlibrary(tidyverse)\nlibrary(maps)\nlibrary(kableExtra)\n\n# Color schemes\n# stata for climate zones\n# tableau('tableau10') for sample set\n# tableau('greenorange12') for building type\n```\n\n# Introduction\n\nProject EDIFES now has 779 cleaned building datasets ingested into HBase and \n(around) 20 working building markers. The purpose of this report is to \ndocument preliminary work towards a complete cross-sectional study of all\nbuildings and markers. \n\nTo see a comprehensive documentation of my work, see my [preliminary final report](https://drive.google.com/open?id=1I6rfP6YSwA2LILQAmgGh3diijancN-WC). \nAny comments and criticism would be much appreciated so I can improve the report\nbefore submission.\n\n## Data Characteristics\n\n* Total of 779 buildings\n* 209 buildings have square feet readings\n    + 92 of these are 'accurate' and 117 are estimated\n* 424 buildings have a standardized building type\n* 155 buildings have number of floors information\n\n\n## Markers \n\n__Markers constantly change and results presented here reflect markers as of 12/1/2017.__\n\n* Markers run on all building are as follows\n    + Heating Type\n    + EUI (where applicable)\n    + Effective Thermal Resistance (where applicable)\n    + Base-to-Peak Ratio\n    + Summary Statistics\n    + Data Quality Check\n    + HVAC Size\n    + HVAC Schedule\n* Additional analysis covers\n    + Climate zone (kgcz and ASHRAE) distribution\n    + Annual Consumption\n    + Correlations between weather conditions and electricity consumption\n  \n# Building Types\n\nResults were obtained via the StandardizeBuildingTypes function written by Shreyas Kamath. \n\n```{r, include = FALSE}\n# Basic statistics\nenergy_meta <- read_csv('../data/meta_12-06.csv')\nsum(energy_meta$sqft != '' & energy_meta$dscr == 'Accurate', na.rm = TRUE )\nsum(!is.na(energy_meta$buts) & !is.null(energy_meta$buts) & energy_meta$buts != '', na.rm = TRUE)\nsum(energy_meta$sqft != '' & energy_meta$dscr == 'Accurate', na.rm = TRUE )\nsum(energy_meta$flrs != '', na.rm = TRUE)\n```\n\n```{r, echo = FALSE}\n# Sampleset to understandable names\nstypes <- list(sampleset2 = 'JCI2', sampleset3 = 'JCI2_ex', sampleset4 = 'FirstE', \n               sampleset5 = 'Prog', sampleset6 = 'KSU', sampleset7 = 'Starbucks', \n               sampleset8 = 'FirstE_ex', sampleset9 = 'CWRU', sampleset10 = 'Schools')\n\nunderstand <- sapply(energy_meta$styp, function(x) {return(as.character(stypes[[x]]))})\nenergy_meta$styp <- understand\n\n# Building type information\ntypes <- as.data.frame(table(energy_meta$buts))\nnames(types) <- c('type', 'count')\nknitr::kable(types, format = 'html') %>% \n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('Standardized Building Types' = 2))\n```\n\nCompletely pointless wordcloud of building types.\n\n```{r}\nlibrary(wordcloud)\npal <- brewer.pal(9, 'PuOr')\nwordcloud(types$type, types$count,  min.freq = 1, colors = pal,\n          main = 'Building Types')\n```\n\n\n\n# Climate Zone Distribution\n\nResults were obtained via functions I wrote for kgcz (mrk-climate_identifier.R)\nand ASHRAE (mrk-get_ashrae_cz.R) climate zone identification from latitude and \nlongitude. The KGCZ is based on latitude and longitude with 0.5 degree precision,\nand the ASHRAE climate zone is based on querying the United States Census Bureau\nAPI to retrieve the county and matching that to a list of counties and climate zones. \n\n## Koppen Geiger Climate Zones\n\nImage to orient ourselves. \n\n```{r, echo = FALSE, fig.height = 4, fig.width = 5.5}\nknitr::include_graphics('KG_USA.gif')\n```\n\n### Table of KGCZ climate zone counts\n\n\n```{r, echo = FALSE}\nkgcz <- energy_meta %>% group_by(kgcz) %>% summarise(count = n())\nkgcz <- kgcz[which(kgcz$kgcz != ''), ]\nknitr::kable(kgcz, format = 'html') %>% \n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('KGCZ Counts' = 2))\n```\n\n### Plot of KGCZ Distribution\n\n```{r, echo = FALSE}\n# Plot of proportions of climate zones\nggplot(kgcz, aes(x = kgcz, y = count / sum(count))) + \n  geom_bar(fill = 'darkgreen', stat = 'identity') +\n  xlab('KGCZ') + ylab(\"Proportion\") + ggtitle('KGCZ Proportions') + \n  theme_classic(12) + scale_y_continuous(breaks = seq(0, 0.6, 0.1))\n\npct_kgcz_2 <- sum(energy_meta$kgcz == 'Cfa' | energy_meta$kgcz == 'Dfa', na.rm = TRUE) / nrow(energy_meta)\n```\n\n* 75% of building occurs in just 2 climate zones, Cfa and Dfa. \n* 4 climate zones have over 30 buildings (level of statistical significance according \nto the [central limit theorem](http://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_probability/BS704_Probability12.html))\n\n## ASHRAE Climate Zones\n\nImage to orient ourselves\n\n```{r, echo = FALSE, fig.width=5.5, fig.height=4}\nknitr::include_graphics('Figure-B-1-United-States-Climate-Zone-Map.png')\n```\n\n### Table of ASHRAE Climate Zones\n\n```{r, echo = FALSE}\na_cz <- energy_meta %>% group_by(a_cz) %>% summarize(count = n())\na_cz <- a_cz[which(a_cz$a_cz != ''), ]\n\nknitr::kable(a_cz, format = 'html') %>% \n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('ASHRAE CZ Counts' = 2))\n```\n\n### Plot of ASHRAE Climate Zone Distributions\n\n```{r, echo = FALSE}\n# Plot ASHRAE Climate Zone Proportions\nggplot(a_cz, aes(x = a_cz, y = count / sum(count))) + \n  geom_bar(fill = 'darkgreen', stat = 'identity') +\n  xlab('ASHRAE CZ') + ylab(\"Proportion\") + ggtitle('ASHRAE CZ Proportions') + \n  theme_classic(12) + scale_y_continuous(breaks = seq(0, 0.6, 0.1))\n\npct_ashrae_2 <- (sum(energy_meta$a_cz == '4A' | energy_meta$a_cz == '5A', na.rm = TRUE)) / nrow(energy_meta)\n```\n\n* 85.6% of buildings are in two climate zones, 4A and 5A\n* 4 climate zones with more than 30 buildings\n\n# Data Quality \n\nData quality check building currently does not work for 35 datasets (all those with\n1 minute interval data).\n\n* 4 letter grades represent quality before and after cleaning\n* These statistics were not computed on the actual raw data for these datasets\n\n## Data Quality standards\n\n```{r echo = FALSE}\nknitr::include_graphics('data_quality_standards.PNG')\n```\n\n## Plot of All Quality before and after\n\n```{r}\n# Select the quality\nquality <- dplyr::select(energy_meta, styp, dq_b, dq_a, s_name)\nquality <- quality[which(quality$dq_a != '' & quality$dq_b != ''), ]\n\n# Gather into long format\nquality_long <- gather(quality, key = 'state', value = 'quality', dq_b, dq_a)\nquality_long <- quality_long[which(quality_long$quality != ''), ]\nquality_long <- arrange(quality_long, desc(state))\n\n# Bar Plot of Quality\nggplot(quality_long, aes(x = quality, fill = state)) + \n  geom_bar(position = 'dodge', width = 0.8) + \n  scale_fill_manual(values = c('darkgreen', 'orange'), labels = c('after', 'before')) + \n  xlab('Quality') + ggtitle('Data Quality Before and After Cleaning') + \ntheme_classic(12) + theme(axis.text.x = element_text(angle = 90))\n```\n\n## Data Quality Changes through Cleaning\n\nThis shows all changes with more than 5 occurrences.\n\n```{r}\n# Establish datasets that had a change in quality\nquality_change <- quality[(which(quality$dq_a != quality$dq_b)), ]\nquality_change <- quality_change[which(\n  quality_change$dq_b != '' & quality_change$dq_b != ''), ]\n\n# Create a column showing change in quality\nquality_change$change <- paste(quality_change$dq_b, quality_change$dq_a, sep = '->') \nquality_change <- group_by(quality_change, change) %>% summarize(count = n())\nquality_change <- dplyr::filter(quality_change, count >= 5)\n\n# Plot the changes in quality with horizontal bar chart\nggplot(quality_change, aes(x = change, y = count)) + geom_bar(fill = 'firebrick', \n                                                              stat = 'identity') + \n   ggtitle(\"Data Quality Changes with 5 or more Occurrences\") + \n  xlab(\"Change (before -> after)\") + theme_classic(12) + \n  scale_y_continuous(breaks = seq(0, 30, 5)) + \n  theme(axis.text = element_text(color = 'black'), axis.title = element_text(size = 14)) +\n  coord_flip()\n```\n\n## Data Quality by Sample Set\n\nNow, to highlight the datasets that were not AAAP.\n\n```{r}\n# Table of Data Quality before Cleaning \nquality_b <- as.data.frame(table(quality$styp, quality$dq_b))\nquality_b <- spread(quality_b, key = Var2, value = Freq)\nnames(quality_b)[1] <- 'Sampleset'\n\n# Filter out highest quality data\nquality_b <- quality_b[, -which(names(quality_b) == 'AAAP')]\n\nknitr::kable(quality_b, format = 'html') %>% \n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('Non AAAP Quality before Cleaning' = 12))\n\n# Quality after cleaning\nquality_a <- as.data.frame(table(quality$styp, quality$dq_a))\nquality_a <- spread(quality_a, key = Var2, value = Freq)\nnames(quality_a)[1] <- 'Sampleset'\n\n# Filter out highest quality data\nquality_a <- quality_a[, -which(names(quality_a) == 'AAAP')]\n\n\nknitr::kable(quality_a, format = 'html') %>% \n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>% \n  add_header_above(header = c('Non AAAP Quality after Cleaning' = 7))\n\n```\n\n## Plots of data quality by sample set\n\n```{r}\nggplot(dplyr::filter(quality, dq_b != 'AAAP'), aes(x = dq_b, fill = styp)) + \n  geom_bar( position = 'dodge') + xlab('Quality Before Cleaning') + \n  ggtitle(\"Non AAAP Data Quality Before Cleaning by Sample Set\") + \n  theme_classic(12) + theme(axis.text.x = element_text(angle = 90)) + \n  scale_fill_tableau()\n\nggplot(dplyr::filter(quality, dq_a != 'AAAP'), aes(x = dq_a, fill = styp)) + \n  geom_bar( position = 'dodge') + xlab('Quality After Cleaning') + \n  ggtitle(\"Non AAAP Data Quality After Cleaning by Sample Set\") + \n  theme_classic(12) + theme(axis.text.x = element_text(angle = 90)) + \n  scale_fill_tableau()\n```\n\n# Heating Type\n\n```{r, echo = FALSE}\n# Generate the heating ID\nheating_id <- function(x) {\n  if (is.na(x)) {\n    return(NA)\n  }\n  if (startsWith(x, \"Electric Heating\")) {\n    return(\"Electric\")\n  } else {\n    return('Non Electric')\n  }\n}\n\n# Convert heating type\nenergy_meta$heating_type <- sapply(energy_meta$bc_4, heating_id)\n\n# Heating type and climate zone\nheating_kgcz <- dplyr::select(energy_meta, kgcz, heating_type, buts)\nheating_kgcz <- heating_kgcz[which(heating_kgcz$kgcz != '' & !is.na(heating_kgcz$heating_type)), ]\n\nggplot(heating_kgcz, aes(heating_type, fill = kgcz)) + geom_bar(position = 'dodge') + \n  ggtitle('Heating Type by Climate Zone') + theme_classic(12) + scale_fill_stata()\n```\n\n## Heating Type by Location\n\nIn the following map, the Starbucks locations are the stars. These demonstrate\nconsiderably different behavior than the other buildings which might \nexplain why they are classified as non-electrical heating despite\nbeing located in the Southwest. \n\n```{r}\n# Fetch the US map\nus <- map_data('state')\n\nheating_type <- dplyr::select(energy_meta[which(!is.na(energy_meta$heating_type)), ], \n                              buts, kgcz, styp, heating_type, wets, long, lati, zpcd)\nheating_type$shape <- ifelse(heating_type$styp == 'Starbucks', 8, 19)\n\n# Plot the map and data\nggplot(us, aes(x = long, y = lat, group = group)) + \n  geom_polygon(color = 'black', fill = 'gray') + coord_map() + theme_void() + \ngeom_point(data = heating_type, aes(x = as.numeric(long), y = as.numeric(lati),\n               group = zpcd, color = heating_type, shape = as.factor(shape)), \n           alpha = 0.8, size = 4) + \n  scale_color_manual(values = c('red', 'blue')) + \n  scale_shape_manual(values = c(8, 19), \n                     labels = c('Starbucks', 'Other'), guide = 'legend') + \n  ggtitle('Heating Type by Location') + labs(shape = '') +\n  theme(plot.title = element_text(hjust = 0.5), legend.position = 'bottom') \n\n```\n\n## Heating Type Determination\n\nThe current process to determine the heating type is as follows\n\n* Data subset to business days between 7 am and 7 pm\n* Linear model between energy use and temperature\n* Slope is extracted from the model\n* Cut point is set at a slope of 0\n* Negative slope indicates electrical heating\n* Positive slope indicates non-electrical (gas or no?) heating \n* Winter and summer temperatures determined from changepoint analysis\n\nExample plot of heating type. Conclusion from this plot is\nelectrical heating. \n\n```{r}\nknitr::include_graphics('heating_type_results.png')\n\n```\n\nEverything to the right of the black vertical line in the following plot\nis classified as non-electrical heating while everything to the left\nis classified as electrical. \n\n```{r}\n# Select the relevant variables\nwets <- dplyr::select(energy_meta, kgcz, a_cz, wets, sets, butp, heating_type)\nwets <- wets[which(!is.na(wets$kgcz)), ]\nwets <- wets[which(wets$kgcz != 'BWh' & wets$kgcz != 'BWk'), ]\n\n# Plot the distribution\n# ggplot(wets, aes(x = wets, fill = kgcz, group = kgcz)) + \n#          geom_histogram() + \n#   xlab('Winter Slope between Energy Use and Temperature') + \n#   ggtitle('Distribution of Winter Slope between Energy and Temperature') + \n#   scale_x_continuous(limits = c(-0.5, 0.5), breaks = seq(-0.5, 0.5, 0.1)) +\n#   theme_classic(12) + geom_vline(xintercept = 0, col = 'black', lwd = 1.2) + \n#   scale_fill_stata()\n\n```\n\nWe can segment the plot to between -0.1 and 0.1 because the majority\nof slopes fall in that range.\n\n```{r}\n# Similar Plot but reduce the range\nggplot(wets, aes(x = wets, color = kgcz, group = kgcz)) + \n         geom_freqpoly(lwd = 1.6) + \n  scale_color_stata() + xlab('Winter Slope between Energy Use and Temperature') + \n  ggtitle('Distribution of Winter Slope Energy and Temp') + \n  scale_x_continuous(limits = c(-0.1, 0.1), breaks = seq(-0.1, 0.1, 0.01)) +\n  theme_classic(12) + geom_vline(xintercept = 0, col = 'black', lwd = 1.2) + \n  theme(axis.text.x = element_text(angle = 90, vjust = -0.1))\n\n```\n\nThe question is where to draw the line for electrical heating. Currently the \ncut point is at a slope of 0, but this might need to be adjusted or we\nneed to use a different method. \n\nI developed a Shiny Interactive application that lets us \nsee the effects of altering the breakpoint for the slope on the heating\ntype classification. We could adjust the slope breakpoint until it lines\nup with the buildings for which we know the answer.\n\n## [Interactive application](https://willkoehrsen.shinyapps.io/heating_type/)\n\nThoughts? \n\n# Annual Consumption\n\n## Annual Consumption in kWh\n\nThis is annual consumption for the most recent year.\n\n### Summary Statistics\n\n```{r}\n# Calculate and display summary statistics\nannc <- dplyr::select(energy_meta, annc)\nsum_annc <- as.data.frame(unclass(summary(annc$annc)))\nnames(sum_annc) <- 'stat'\n\nknitr::kable(sum_annc, format = 'html') %>%\n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('Annual Consumption Stats' = 2))\n```\n\n### Histogram of Annual Energy Use\n\nThe red vertical line is the median at 2.349e6 kWh per year. \n\n```{r}\n# Plot the annual energy use\nggplot(annc , aes(x = annc)) + geom_histogram(col = 'black', fill = 'navy') + \n  scale_x_log10() + \n  xlab('Log10 Annual Energy (kWh)') + ggtitle('Log10 of Annual Consumption') + \n  theme_classic(12) +  \n  geom_vline(xintercept = median(annc$annc, na.rm = TRUE), col = 'red', lwd  = 1.2) \n\n```\n\n# Energy Use Intensity, Effective R Value\n\nThe energy use intensity (EUI) of a building is meant to compare buildings of different\nsizes in the same climate zone and of the same type. The EUI is designed to normalize\nthe size of a building and EUI values differe significantly across industries. \n\n* A lower EUI value indicates a more efficient building for its class\n\nThe effective thermal resistance (r-value) of a building is a measure of the \nbuildings resistance to heat loss. It can be used as a measure of the 'tightness'\nof a building's insulation.\n\n* A higher R value indicates a better insulated and sealed building\n\nAs long as we have the accurate sqaure footage and energy consumption, we \nshould get the correct EUI value. However, the effective thermal resistance\nrequires more complex thermodynamic analysis. \n\n## Energy Use Intensity\n\n201 buildings have an energy use intensity value. \n\n```{r}\n# Select the buildings with EUI values\neui <- dplyr::select(energy_meta, bc_5, buts)\neui <- eui[which(!is.na(eui$bc_5)), ]\neui[which(is.na(eui$buts)), ]$buts <- 'None'\n\n# Group by standardized building type\neui_buts <- group_by(eui, buts) %>% \n  summarize(count = n(), mean = round(mean(bc_5, na.rm = TRUE), 2),\n            median = round(median(bc_5, na.rm = TRUE), 2), \n            sd = round(sd(bc_5, na.rm = TRUE), 2))\n\n# Read in median EUI values from Energy Star\nmedian_eui <- read_csv('../data/site-eui-median-bldg-type.csv')\nmedian_eui <- median_eui[, which(names(median_eui) %in% c('Type', 'Subtype', 'Value'))]\n\n\n# Group by type\nmedian_eui <- group_by(median_eui, Type) %>%\n  summarize(reference = mean(Value, na.rm = TRUE))\n\n# Manually enter in Starbucks median EUI\nmedian_eui[which(startsWith(median_eui$Type, 'Food Sales')), ]$reference <- 229.85\n\neui_buts <- merge(eui_buts, median_eui, by.x = 'buts', by.y = 'Type', all.x = TRUE)\n\neui_buts <- eui_buts[which(eui_buts$buts != 'NULL' & eui_buts$buts != 'None'), ]\neui_buts[which(eui_buts$buts == 'Office'), ]$reference <- 67.3\n\nknitr::kable(eui_buts, format = 'html') %>% \n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('EUI Stats by Building Type' = 7))\n```\n\nA good visualization for the distribution of EUI values is a boxplot.\nI filtered out EUI values greater than 500 which are highly suspect.\n\n```{r}\n# Boxplots for EUI by building type\nggplot(dplyr::filter(eui, bc_5 < 500),\n       aes(x = buts, y = bc_5, fill = buts, group = buts)) + \n  geom_boxplot() + theme_classic(12) + xlab('Building Type') + \n  geom_point(data = eui_buts, aes(x = buts, y = reference), col = 'red', size = 4, shape = 8) + \n  ylab('Building EUI (kBTU/ft^2)') + ggtitle('Building EUI Boxplots') + \n  coord_flip() + labs(fill = 'Building Type') +\n  theme(axis.text = element_text(color = 'black')) + scale_fill_tableau('greenorange12')\n\n```\n\n## Effective Thermal Resistance\n\nTo give a sense of context, vacuum sealed panels, the top of the line insulation,\nhave an effetive r-value of __50 hr F ft^2 / BTU__. \n\n\nIn his thesis, Aaron cites a paper\n([Nordstrom et al. 2013](https://link.springer.com/chapter/10.1007/978-3-642-36645-1_4)[^1]) \nthat examined R - values from 6 residential buildings\nin Sweden built from the 1960s to 2006 to validate the results he obtained from\nhis function. The paper reports R - values between 9.1 to 23.7 hr F ft^2 / BTU. \n\n![^1]G. Nordström, H. Johnsson, and S. Lidelöw, “Using the Energy Signature Method to Estimate the Effective U-Value of Buildings,” in Sustainability in Energy and Buildings, Springer, Berlin, Heidelberg, 2013, pp. 35–44.\n```{r}\n# Extract the r-value and display results by building type\nr_value <- dplyr::select(energy_meta, bc_6, buts)\nr_value <- r_value[which(!is.na(r_value$bc_6)), ]\nr_value[which(is.na(r_value$buts)), ]$buts <- 'None'\n\nr_buts <- group_by(r_value, buts) %>% \n  summarize(count = n(), mean = round(mean(bc_6, na.rm = TRUE), 2),\n            median = round(median(bc_6, na.rm = TRUE), 2), \n            sd = round(sd(bc_6, na.rm = TRUE), 2))\n\nr_buts <- r_buts[which(r_buts$buts != 'NULL'), ]\n\nknitr::kable(r_buts, format = 'html') %>%\n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('Effective Thermal Resistance Stats by Building Type' = 5))\n```\n\nBoxplots of Effective Thermal Resistance. The red vertical lines indicate\nthe typical range as reported in the paper.\n\n```{r}\n# Boxplots for EUI by building type with typical range from paper\nggplot(dplyr::filter(r_value, bc_6 < 200), \n       aes(x = buts, y = bc_6, fill = buts, group = buts)) + \n  geom_boxplot() + theme_classic(12) + xlab('Building Type') + \n  ylab('Effective Thermal Resistance (hr * F * ft^2 / BTU') + ggtitle('Building R-Value Boxplots') + \n  coord_flip() + labs(fill = 'Building Type') +\n  geom_hline(yintercept = 9.1, col = 'red', lwd = 1.2) + \n  geom_hline(yintercept = 23.7, col = 'red', lwd = 1.2) + \n  scale_fill_tableau('greenorange12')\n```\n\nThis function needs some work, and I plan on addressing it over winter break. \nIt is based on a thermodynamic model as documented by Aaron in his paper. Professor Abramson\nhas validated the method, but the implementation might need an adjustment. \nAny ideas would be appreciated. \n\n# Weather Correlations\n\nThe Pearson correlation coefficient measures the strength and direction \nof a linear relationship between two variables. The following plots show the \nPearson corelation coefficient between weather variables and energy consumption.\n\n* Data subset to operating hours (7 am to 7 pm)\n* Winter: December, January, February\n* Summer: June, July, August\n* Climate zones with only a single building removed\n\n```{r, include = FALSE, eval = FALSE}\n# Choose the relevant columns\ncorrs <- dplyr::select(energy_meta, buts, kgcz, corr)\n\n# Convert character results to a table\nchar_to_tab <- function(merged_data) {\n    \n    # spliting the rows\n    \n    tab_row <- as.data.frame(strsplit(as.character(merged_data), \"#\"))\n    \n    \n    # generating the tabular data for each row\n    tabular_data <- c()\n    for (i in 1:length(tab_row[, 1])) {\n        \n        \n        tab_col <- as.data.frame(strsplit(as.character(tab_row[i, ]), \"\\\\*\"))\n        names(tab_col) <- \"row\"\n        tab_col <- as.data.frame(t(tab_col))\n        tabular_data <- rbind(tabular_data, tab_col)\n        \n    }\n    \n    # change col names and take out the firs row because it is the colnames\n    \n    colnames(tabular_data) <- as.character(unlist(tabular_data[1, ]))\n    tabular_data <- tabular_data[-c(1), ]\n    \n    return(tabular_data)\n    \n}\n\n# Apply the conversion\ncorrs$df <- sapply(corrs$corr, char_to_tab)\ncorrs <- corrs[which(!is.na(corrs$kgcz)), ]\n\n# Create a data frame to hold all correlations\nweather_df <- as.data.frame(matrix(ncol = 4))\nnames(weather_df) <- c('weather', 'season', 'value', 'kgcz')\n\n# Fill in the dataframe\nextract_weather_corrs <- function(index, weather_corrs) {\n  kgcz <- weather_corrs[index, ]$kgcz\n  \n  corr_df <- as.data.frame(weather_corrs[[index, 'df']])\n  \n  # Iterate through rows \n  for (i in 1:nrow(corr_df)) {\n    season <- as.character(corr_df[i, ]$season)\n    weather <- as.character(corr_df[i, ]$variable)\n    value <- as.numeric(as.character(corr_df[i, ]$correlation))\n    weather_df <<- add_row(weather_df, weather = weather, season = season,\n                           value = value, kgcz = kgcz)\n  }\n  weather_df <<- weather_df[complete.cases(weather_df), ]\n  \n}\n\n# Actually fill in the dataframe with this command\nresults <- sapply(1:nrow(corrs), FUN = extract_weather_corrs, weather_corrs = corrs)\n\n```\n\n## Boxplots of Correlations\n\n```{r}\nload('weather_df')\nweather_df <- dplyr::filter(weather_df, kgcz != 'BWh', kgcz != 'BWk')\n\n# Boxplots faceted by season\nggplot(dplyr::filter(weather_df, weather == 'temp'), aes(x = kgcz, y = value, fill = kgcz)) + \n  geom_boxplot() + theme_hc(12) + facet_wrap(~season, ncol = 1) + \n  xlab('kgcz') + ylab('Correlation Coefficient') + \n  ggtitle('Correlation Coefficients between Energy and Temp') + scale_fill_stata()\n\n# Boxplots faceted by season\nggplot(dplyr::filter(weather_df, weather == 'ghi'), aes(x = kgcz, y = value, fill = kgcz)) + \n  geom_boxplot() + theme_hc(12) + facet_wrap(~season, ncol = 1) + \n  xlab('kgcz') + ylab('Correlation Coefficient') + \n  ggtitle('Correlation Coefficients between Energy and GHI') + scale_fill_stata()\n\n# Boxplots faceted by season\nggplot(dplyr::filter(weather_df, weather == 'rh'), aes(x = kgcz, y = value, fill = kgcz)) + \n  geom_boxplot() + theme_hc(12) + facet_wrap(~season, ncol = 1) + \n  xlab('kgcz') + ylab('Correlation Coefficient') + \n  ggtitle('Correlation Coefficients between Energy and Relative Humidity') + scale_fill_stata()\n\n```\n\n## Heatmaps for Climate Zones and Weather Variables\n\nThe following heatmaps show the average correlations between weather conditions \nenergy consumption by climate zone. The dendograms cluster similar \nweather conditions and similar climate zones. \n\n```{r}\nlibrary(gplots)\n\n# Separate dataframes for summer and winter\nsummer_weather <- weather_df[which(weather_df$season == 'summer'), ]\nwinter_weather <- weather_df[which(weather_df$season == 'winter'), ]\n\n# Summarizing the data for winter\nwinter_weather <- group_by(winter_weather, kgcz, weather) %>%\n  summarize(value = mean(value, na.rm = TRUE)) %>% \n  spread(key = weather, value = value)\n\nwinter_weather_m <- round(as.matrix(winter_weather[, -1]), 3)\nrownames(winter_weather_m) <- winter_weather$kgcz\n\n# Summarizing the data for summer\nsummer_weather <- group_by(summer_weather, kgcz, weather) %>%\n  summarize(value = mean(value, na.rm = TRUE)) %>% \n  spread(key = weather, value = value)\n\nsummer_weather_m <- round(as.matrix(summer_weather[, -1]), 3)\nrownames(summer_weather_m) <- summer_weather$kgcz\n\nwinter_weather_m <- winter_weather_m[, colnames(summer_weather_m)]\n\n# Create a custom palette \nmy_palette <- colorRampPalette(c(\"blue\", \"orange\", \"red\"))(n = 59)\n\n# Define color breaks custom\ncol_breaks = c(seq(-1,-0.25,length = 20),\n  seq(-0.24,0.24,length = 20),          \n  seq(0.25,1,length = 20))             \n\n# Heatmap for summer correlation\nheatmap.2(summer_weather_m,\n          dendrogram = \"both\",   # Only cluster rows\n  cellnote = summer_weather_m,  # Cell labels\n  cexRow = 1.2, # Adjust size of row labels\n  cexCol = 1.2, # Adjust size of column labels\n  notecex = 1.2, # Adjust size of cell labels\n  main = \"Summer Correlation Coefficients\", # Title\n  notecol = \"black\",      # Change the fontcolor of cell labels\n  density.info = \"none\",      # widens margins around plot\n  col = my_palette,      # Use defined color palette\n  breaks = col_breaks,   # Use custom color breaks\n  trace = 'none', # Turn off cell trace\n  lwid = c(0.28, 0.80),     # Adjust width \n  lhei = c(0.3, 0.68))      # Adjust height\n\n# Heatmap for winter correlation\nheatmap.2(winter_weather_m,\n          dendrogram = \"both\",   # Only cluster rows\n  cellnote = winter_weather_m,  # Cell labels\n  cexRow = 1.2, # Adjust size of row labels\n  cexCol = 1.2, # Adjust size of column labels\n  notecex = 1.2, # Adjust size of cell labels\n  main = \"Winter Correlation Coefficients\", # Title\n  notecol = \"black\",      # Change the fontcolor of cell labels\n  density.info = \"none\",      # widens margins around plot\n  col = my_palette,      # Use defined color palette\n  breaks = col_breaks,   # Use custom color breaks\n  trace = 'none', # Turn off cell trace\n  lwid = c(0.28, 0.80),     # Adjust width \n  lhei = c(0.3, 0.68))      # Adjust height\n\n\n```\n\n# Base Peak Ratio\n\nThe base to peak ratio is the average base load divided by the average peak load.\nThis marker is segmented by winter and summer and by year so we can look \nat changes between the seasons as well as changes over the years. \n\n* Base peak ratio > 0.30 indicates an opportunity for savings by reducing the base load.\n\nWe can first look at the base to peak ratio statistics for the final year by sample set.\nThese tables are grouped by season and arranged from lowest (best) to highest (worst)\nbase to peak ratio. \n\n* pct_savings indicates the percentage of buildings in the sample set that\ncan save by reducing baseload. \n\n## Statistics by Sample Set\n\n```{r, echo = FALSE, eval = FALSE}\nbase_peak <- dplyr::select(energy_meta, kgcz, bc_7)\nbase_peak$df <- lapply(base_peak$bc_7, FUN = char_to_tab)\n\nbase_peak$buts <- energy_meta$buts\nbase_peak$s_name <- energy_meta$s_name\nbase_peak$styp <- energy_meta$styp\n\nbase_results <- as.data.frame(matrix(ncol = 4))\nnames(base_results) <- c('s_name', 'year', 'season', 'ratio')\n\nexample <- as.data.frame(base_peak$df[1])\n\n# Iterate through all the base peak dataframes\nfor (index in 1:nrow(base_peak)) {\n  df <- as.data.frame(base_peak$df[index])\n  name <- base_peak$s_name[index]\n  if (nrow(df) != 0) {\n    # Iterate through all the rows in the base peak dataframe\n    for (row_index in 1:nrow(df)) {\n  \n      info <- df[row_index, ]\n      base_results <- add_row(base_results, s_name = name, year = info$year,\n                              season = info$season, ratio = info$base.peak.ratio)\n    }\n  }\n}\n\nbase_results <- base_results[complete.cases(base_results), ]\n```\n\n```{r, echo = FALSE}\nload('base_results')\nbase_results$ratio <- as.numeric(base_results$ratio)\nbase_results$year <- as.numeric(base_results$year)\n\n# A positive first - last is good as it indicates a decrease\nbase_summary <- group_by(base_results, s_name, season) %>%\n  summarize(count = n(), first_ratio = ratio[which.min(year)], \n            last_ratio = ratio[which.max(year)]) %>% \n  mutate(ratio_change = first_ratio - last_ratio, decrease = first_ratio > last_ratio)\n\n# Get the climate zones, building type, and sample set information\nbase_summary <- merge(base_summary, \n                      dplyr::select(energy_meta, kgcz, buts, s_name, styp), \n                      by = 's_name', all.x = TRUE)\n\n# Actual ratio grouped by the sample set and season \nstyp_base <- group_by(base_summary, styp, season) %>%\n  summarize(count = n(), mean = mean(last_ratio), median = median(last_ratio),\n            sd = sd(last_ratio), pct_savings = (sum(last_ratio > 0.3)) / count)\n\nstyp_winter_base <- dplyr::filter(styp_base, season == 'winter') %>%\n  arrange(mean)\n\nstyp_summer_base <- dplyr::filter(styp_base, season == 'summer') %>%\n  arrange(mean)\n\nknitr::kable(styp_winter_base, format = 'html') %>%\n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('Winter Base Load Stats by Sample Set' = 7))\n\nknitr::kable(styp_summer_base, format = 'html') %>%\n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('Summer Base Load Stats by Sample Set' = 7))\n\n```\n\nWe can also look at boxplots for each sampleset. The blue vertical line\nindicates the threshold established for savings opportunities.\n\n```{r}\n# Plot of actual ratio by season\nggplot(base_summary, aes(x = styp, y = last_ratio, fill = styp)) + geom_boxplot() + \n  theme_hc(12) + facet_wrap(~ season) + xlab('sampleset') + \n  ggtitle('Base Peak Ratio') + coord_flip() + scale_fill_tableau() + ylab('ratio') + \n  theme(panel.grid.major.x = element_line(color = 'grey40', size = 0.1),\n        panel.background = element_rect(fill = 'navajowhite')) + \n    labs(fill = '') + geom_hline(yintercept = 0.3, col = 'navy', lwd = 1.2)\n```\n\n## Summer Versus Winter Ratio\n\nAs a sanity check, we can look at a plot showing the relationship \nbetween the ratio during the summer and winter. We would expect this to \nbe a positively linear relationship.\n\n```{r}\n# Spread the season column into two columns\nsummary_plot <- spread(data = base_summary, key = 'season', value = 'last_ratio') %>%\n  group_by(s_name) %>% summarize(summer = mean(summer, na.rm = TRUE), \n                                 winter = mean(winter, na.rm = TRUE))\n# Add the sample set\nstyp <- dplyr::select(energy_meta, styp, s_name)\nsummary_plot <- merge(summary_plot, styp)\n\n# Plot summer versus winter ratio\nggplot(summary_plot, aes(x = winter, y = summer, col = styp)) + geom_jitter() +\n  theme_stata(12) + xlab('Winter Ratio') + ylab('Summer Ratio') + \n  ggtitle('Summer Ratio vs Winter Ratio') + scale_color_tableau()\n```\n\n## Yearly Changes in Ratio\n\nThe base to peak ratio is calculated for each year, so we can look at\nthe changes over the years to see which buildings are improving. \n\n* Change is defined as oldest ratio - most recent ratio\n* Positive change indicates reduction in ratio\n* Calculated only for buildings with more than one year of base load data\n\n```{r}\n# Frequyency polygon of ratio change\nggplot(dplyr::filter(base_summary, count > 1), \n       aes(x = ratio_change, color = styp)) + geom_freqpoly(lwd = 1.1) + \n  xlab('Ratio Change') + ggtitle('Ratio Change Frequency Polygon') + \n  facet_wrap(~ season, ncol = 1) + \n  scale_x_continuous(breaks = seq(-0.4, 0.4, 0.1)) + \n  scale_color_tableau() + theme_hc(12)\n\n# Plot of change from first year to last year\nggplot(dplyr::filter(base_summary, abs(ratio_change) > 0),\n       aes(x = styp, y = ratio_change, fill = styp)) + geom_boxplot() + \n  theme_hc(12) + facet_wrap(~ season) + xlab('sampleset') + \n  ylab('change in ratio (first - last)') + \n  ggtitle('Change in Base Peak Ratio') + coord_flip() + scale_fill_tableau() +\n  theme(panel.grid.major.x = element_line(color = 'grey40', size = 0.1)) + \n  labs(fill = '')\n```\n\nMost buildings change relatively little, if at all over the years. \nAgain, we can compare seasons to see if there is a correlation between the \nsummer change in base peak ratio and winter change in ratio. \n\nIdeally, a building would be in the upper right quadrant, with positive\nchanges in both summer and winter. \n\n```{r}\n# Summary of changes grouped by sampleset and season\nstyp_change <- group_by(dplyr::filter(base_summary, count > 1), styp, season) %>%\n  summarize(count = n(), mean = mean(ratio_change), median = median(ratio_change),\n            sd = sd(ratio_change))\n\n# Spread the season column into two columns\nchange_season <- spread(data = dplyr::filter(base_summary, count > 1), \n                        key = 'season', value = 'ratio_change') %>%\n  group_by(s_name) %>% summarize(summer = mean(summer, na.rm = TRUE), \n                                 winter = mean(winter, na.rm = TRUE))\n# Add the sample set\nstyp <- dplyr::select(energy_meta, styp, s_name)\nchange_season <- merge(change_season, styp)\n\n# Plot summer versus winter ratio\nggplot(change_season, aes(x = winter, y = summer, col = styp)) + geom_jitter() +\n  theme_stata(12) + xlab('Winter Change') + ylab('Summer Change') + \n  ggtitle('Base Peak Ratio Summer vs. Winter Changes') + scale_color_tableau()\n\nchange_season <- gather(change_season, key = 'season', value = 'ratio', summer, winter)\n\nimprovement <- group_by(change_season, styp, season) %>% \n  summarize(imp_pct = sum(ratio > 0, na.rm = TRUE) / n())\n\nknitr::kable(improvement, format = 'html') %>% \n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('Improvement Percent by Sample Set' = 3))\n\n```\n# Summary Stats\n\n```{r, eval = FALSE}\nsummary_stats <- dplyr::select(energy_meta, s_name, dc_1)\nsummary_stats$df <- lapply(summary_stats$dc_1, char_to_tab)\n\n\nall_means <- as.data.frame(matrix(ncol = 6))\nnames(all_means) <- c('s_name', 'year', 'season', 'mean_energy', 'frequency', \n                      'mean_energy_kw')\n\n# Iterate through all summary stats and extract means\nfor (i in 1:nrow(summary_stats)) {\n  name <- summary_stats$s_name[i]\n  df <- as.data.frame(summary_stats$df[i])\n  \n  # Find the means for the most recent year by season\n  if (nrow(df) > 1) {\n    df$year <- as.numeric(stringr::str_split_fixed(df$variable, '_', n = 2)[, 1])\n    df$season <- stringr::str_split_fixed(df$variable, '_', n = 3)[, 2]\n    df$metric <- stringr::str_split_fixed(df$variable, '_', n = 3)[, 3]\n    df$value <- as.numeric(as.character(df$value))\n  \n    last_summer <- max(df[which(df$season == 'summer'), ]$year)\n    last_winter <- max(df[which(df$season == 'winter'), ]$year)\n    \n    # Find the mean energy consumption for last summer and winter\n    last_summer_mean <- df[which(df$season == 'summer' & df$year == last_summer & \n                                   df$metric == 'mean_cleaned_energy'), ]$value\n    last_winter_mean <- df[which(df$season == 'winter' & df$year == last_winter & \n                                   df$metric == 'mean_cleaned_energy'), ]$value\n    \n    summer_kw <- (60 / frequency) * last_summer_mean\n    winter_kw <- (60 / frequency) * last_winter_mean\n    \n    # Find frequency of data\n    frequency <- as.numeric(df[which(df$variable == 'Frequency'), ]$value)\n    # Add metrics to the results dataframe\n    all_means <- add_row(all_means, s_name = name, year = last_winter,\n                         season = 'winter', mean_energy = last_winter_mean, \n                         frequency = frequency, mean_energy_kw = winter_kw)\n    all_means <- add_row(all_means, s_name = name, year = last_summer,\n                         season = 'summer', mean_energy = last_summer_mean,\n                         frequency = frequency, mean_energy_kw = summer_kw)\n  }\n  \n  \n}\n# Retain only complete entries\nall_means <- all_means[complete.cases(all_means), ]\n```\n\n\n# HVAC Size\n\nThe HVAC size building marker finds the average and maximum size by season.\nIt also finds the average and extreme temperature in each season\nto compare to the HVAC usage.\n\n```{r, eval = FALSE}\n# Initial character hvac size data to lists\nhvac_size <- dplyr::select(energy_meta, s_name, buts, styp, hc_1, kgcz)\nhvac_size$df <- lapply(hvac_size$hc_1, FUN = char_to_tab)\n\n# Dataframe to hold hvac size data\nhvac_s <- as.data.frame(matrix(ncol = 7))\nnames(hvac_s) <- c('s_name', 'year', 'season', 'mean_size', 'ex_size', \n                   'mean_temp', 'ex_temp')\n\n\n# Iterate through all list results, each dataframe\n# contains all the information for a single building\nfor (i in 128:nrow(hvac_size)) {\n  \n  name <- hvac_size$s_name[i]\n  df <- as.data.frame(hvac_size$df[i])\n  \n  if (nrow(df) > 0) {\n    # Iterate through eac row of the building dataframe\n    # Add each season to the overall info dataframe\n    for (n in 1:nrow(df)) {\n       # Information for the season, year\n      row <- df[n, ]\n      \n      # Convert to correct class\n      year <- as.numeric(as.character(row$year))\n      season <- as.character(row$season)\n      mean_size <- as.numeric(as.character(row$hvac_size_kW))\n      ex_size <- as.numeric(as.character(row$extreme_hvac_size))\n      mean_temp <- as.numeric(as.character(row$mean_temp))\n      ex_temp <- as.numeric(as.character(row$extreme_temp))\n      \n      # Add row to information dataframe\n      hvac_s <- add_row(hvac_s, s_name = name, year = year, season = season,\n                        mean_size = mean_size, ex_size = ex_size,\n                        mean_temp = mean_temp, ex_temp = ex_temp)\n    }\n  }\n}\n\n# Get the names, type of building, sample set, and climate zone\nhvac_s2 <- hvac_s[complete.cases(hvac_s), ]\nhvac_s2 <- merge(hvac_s2, hvac_size[, c('s_name', 'buts', 'styp', 'kgcz')], \n                 by = 's_name', all.x = TRUE)\n```\n## Mean HVAC statistics by building type\n\n```{r}\nload('hvac_size')\nload('energy_means')\n\nhvac_size <- merge(hvac_size, energy_means, by = c('s_name', 'year', 'season'))\nhvac_size$norm <- hvac_size$mean_size / hvac_size$mean_energy_kw\n\n# Find the statistics for the most recent year\nhvac_size_mr <- group_by(hvac_size, s_name, season) %>%\n  summarize(mean_hvac = mean_size[which.max(year)], \n   mean_temp = mean_temp[which.max(year)],\n   ex_size = ex_size[which.max(year)],\n   ex_temp = ex_temp[which.max(year)]) %>%\n  merge(energy_meta[, c('s_name', 'styp', 'buts', 'kgcz')], by = 's_name',\n        all.x = TRUE)\n\n# Summary stats for winter\nwinter_hvac_size <- dplyr::filter(hvac_size_mr, season == 'winter') %>%\n  group_by(buts) %>% summarize(number = n(),\n                               mean = mean(mean_hvac, na.rm = TRUE), \n                               median = median(mean_hvac, na.rm = TRUE),\n                               sd = sd(mean_hvac, na.rm = TRUE),\n                               max = max(mean_hvac, na.rm = TRUE),\n                               min = min(mean_hvac, na.rm = TRUE))\n# Round for presentable results\nwinter_hvac_size[, c(3:7)] <- round(winter_hvac_size[, c(3:7)], 1)\n\nknitr::kable(winter_hvac_size, format = 'html') %>%\n  kable_styling(bootstrap_options = c('striped', 'responsive')) %>%\n  add_header_above(header = c('Winter Mean HVAC Stats' = 7))\n\n# Summary stats for winter\nsummer_hvac_size <- dplyr::filter(hvac_size_mr, season == 'summer') %>%\n  group_by(buts) %>% summarize(number = n(),\n                               mean = mean(mean_hvac, na.rm = TRUE), \n                               median = median(mean_hvac, na.rm = TRUE),\n                               sd = sd(mean_hvac, na.rm = TRUE),\n                               max = max(mean_hvac, na.rm = TRUE),\n                               min = min(mean_hvac, na.rm = TRUE))\n# Round for presentable results\nsummer_hvac_size[, c(3:7)] <- round(summer_hvac_size[, c(3:7)], 1)\n\nknitr::kable(summer_hvac_size, format = 'html') %>%\n  kable_styling(bootstrap_options = c('striped', 'responsive')) %>%\n  add_header_above(header = c('Summer Mean HVAC Stats' = 7))\n\n```\n\n## Boxplots for each season by industry\n\nThese boxplots have mean hvac values greater than 500 kW removed.\n\n```{r}\n\n# Boxplot for winter mean HVAC for each industry\nggplot(dplyr::filter(hvac_size_mr, mean_hvac < 500, season == 'winter'), \n       aes(x = buts, y = mean_hvac, fill = buts)) + \n  geom_boxplot() +\n  scale_colour_tableau('greenorange12') + theme_hc(12) + \n  xlab('Building Type') + ylab('Mean HVAC (kW)') + \n  ggtitle(\"Winter Most Recent Mean HVAC by Industry\") + coord_flip() + \n  theme(axis.text = element_text(color = 'black'), \n        plot.title = element_text(hjust = 0.5, size = 14)) + \n  labs(fill = '')\n\n# Boxplot for summer mean HVAC for each industry\nggplot(dplyr::filter(hvac_size_mr, mean_hvac < 500, season == 'summer'), \n       aes(x = buts, y = mean_hvac, fill = buts)) + \n  geom_boxplot() +\n  scale_colour_tableau('greenorange12') + theme_hc(12) + \n  xlab('Building Type') + ylab('Mean HVAC (kW)') + \n  ggtitle(\"Summer Most Recent Mean HVAC by Industry\") + coord_flip() + \n  theme(axis.text = element_text(color = 'black'), \n        plot.title = element_text(hjust = 0.5, size = 14)) + \n  labs(fill = '')\n\n```\n\n\n# HVAC Schedule\n\nThe HVAC schedule function finds the most likely turn on and turn off times\nfor business and non-business days. \n\n## HVAC Schedule by Sample Set\n\nFirst, we can look at business day turn on and turn off times by sample set. \n\n```{r, echo = FALSE, eval = FALSE}\nhvac_sche <- dplyr::select(energy_meta, sc_1, buts)\n\n# Change all the character results to dataframes\nhvac_sche$df <- lapply(hvac_sche$sc_1, FUN = char_to_tab)\nhvac_sche$s_name <- energy_meta$s_name\n\n# Create dataframe with all hvac schedule results\nhvac <- as.data.frame(matrix(ncol = 5))\nnames(hvac) <- c('s_name', 'biz_on', 'biz_off', 'non_on', 'non_off')\n\nfor (index in 1:nrow(hvac_sche)) {\n  # Extract name\n  name <- hvac_sche$s_name[index] \n  \n  # Extract relevant dataframe and convert to correct form\n  df <- as.data.frame(hvac_sche$df[index])\n  \n  if (nrow(df) > 0) {\n  df$Hours <- as.numeric(as.character(df$Hours))\n  df$Minutes <- as.numeric(as.character(df$Minutes))\n  df$pct <- as.numeric(as.character(df$percentage_Occurences))\n  df$day <- as.character(df$day)\n  df$type <- as.character(df$type)\n  \n  # Business day on and off\n  biz_day <- (dplyr::filter(df, day == 'biz'))\n  \n  biz_day_on <- as.numeric(lubridate::hm(paste0(dplyr::filter(biz_day, type == 'on')[\n    which.max(dplyr::filter(biz_day, type == 'on')$pct),]$Hours, ':',\n    biz_day[which.max(dplyr::filter(biz_day, type == 'on')$pct),]$Minutes))) / 3600 \n  \n  biz_day_off <- as.numeric(lubridate::hm(paste0(dplyr::filter(biz_day, type == 'off')[\n    which.max(dplyr::filter(biz_day, type == 'off')$pct),]$Hours, ':',\n    biz_day[which.max(dplyr::filter(biz_day, type == 'off')$pct),]$Minutes))) / 3600\n  \n  # Non business day on and off\n  non_day <- dplyr::filter(df, day == 'non')\n  \n  non_day_on <- as.numeric(lubridate::hm(paste0(dplyr::filter(non_day, type == 'on')[\n    which.max(dplyr::filter(non_day, type == 'on')$pct),]$Hours, ':',\n    biz_day[which.max(dplyr::filter(non_day, type == 'on')$pct),]$Minutes))) / 3600\n  \n  non_day_off <- as.numeric(lubridate::hm(paste0(dplyr::filter(non_day, type == 'off')[\n    which.max(dplyr::filter(non_day, type == 'off')$pct),]$Hours, ':',\n    biz_day[which.max(dplyr::filter(non_day, type == 'off')$pct),]$Minutes))) / 3600\n  \n  hvac <- add_row(hvac, s_name = name, biz_on = biz_day_on, biz_off = biz_day_off,\n                  non_on = non_day_on, non_off = non_day_off)\n  }\n  \n}\n\nhvac <- hvac[complete.cases(hvac), ]\n\n```\n\n```{r, echo = FALSE}\nload('hvac')\nunderstand_hvac <- sapply(hvac$styp, function(x)\n  {return(as.character(stypes[[x]]))})\nhvac$styp <- understand_hvac\nhvac <- merge(hvac, dplyr::select(energy_meta, s_name), by = 's_name')\n```\n\n```{r}\n# Turn on density plot\nggplot(hvac, aes(x = biz_on, fill = styp)) + geom_density(alpha = 0.6) + \n  xlab('Time of day (hrs)') + ylab('Density') + ggtitle('Business Day Turn On Density') + \n  scale_fill_tableau() + scale_x_continuous(breaks = seq(0, 24, 4)) + theme_classic(12)\n\n# Turn off density plot \nggplot(hvac, aes(x = biz_off, fill = styp)) + geom_density(alpha = 0.6, ) + \n  xlab('Time of day (hrs)') + ylab('Density') + ggtitle('Business Day Turn Off Density') + \n  scale_fill_tableau() + scale_x_continuous(breaks = seq(0, 24, 4)) + theme_classic(12)\n\n\n```\n\nOne other thing to look at is typical length of operating day.\n\n```{r, echo = FALSE}\nhvac$hrs <- abs(hvac$biz_on - hvac$biz_off)\n \nhvac_day <- group_by(hvac, styp) %>%\n  summarize(mean_on = mean(biz_on, na.rm = TRUE), mean_off = mean(biz_off, na.rm = TRUE)) %>%\n  mutate(hours = abs(mean_off - mean_on))\n\nhvac_day[, -1] <- round(hvac_day[, -1], 3)\n\nknitr::kable(hvac_day, format = 'html') %>% \n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('Average HVAC Schedule by Sample Set' = 4))\n\n```\n\n# Correlations\n\nWe can make some correlation plots to determine relationships that \nexist between building markers. The quantitative numbers can also be\nprinted to look at the possible trends.\n\n```{r, echo = FALSE}\n\n# Create a new data frame with the variables for correlations\n# Looking at correlations between annc, eui, r, summer ratio, winter ratio, hours\nenergy_meta2 <- dplyr::select(energy_meta, s_name, annc, bc_5, bc_6)\nnames(energy_meta2) <- c('s_name', 'annc', 'eui', 'r')\n\nbase_winter <- base_summary[which(base_summary$season == 'winter'), ]\nbase_summer <- base_summary[which(base_summary$season == 'summer'), ]\n\nbase_winter <- dplyr::select(base_winter, s_name, last_ratio)\nnames(base_winter) <- c('s_name', 'winter_base')\n\nbase_summer <- dplyr::select(base_summer, s_name, last_ratio)\nnames(base_summer) <- c('s_name', 'summer_base')\n\nenergy_meta2 <- merge(energy_meta2, base_summer, by = 's_name', all.x = TRUE)\nenergy_meta2 <- merge(energy_meta2, base_winter, by = 's_name', all.x = TRUE)\n\nenergy_meta2$log_annc <- log(energy_meta2$annc, base = 10)\nenergy_meta2 <- energy_meta2[which(energy_meta2$eui < 500), ]\nenergy_meta2 <- merge(energy_meta2, dplyr::select(hvac, s_name, hrs))\nnames(energy_meta2) <- c('s_name', 'annc', 'eui', 'r', 'summer_ratio', \n                         'winter_ratio', 'log_annc', 'hours')\n\nenergy_mat <- as.matrix(energy_meta2[, -c(1, 2)])\nenergy_mat <- energy_mat[complete.cases(energy_mat), ]\n\n# Make a correlation matrix\ncorr_energy <- cor(energy_mat)\n\nknitr::kable(corr_energy, format = 'html') %>% \n  kable_styling(bootstrap_options = c('striped', 'hover', 'responsive')) %>%\n  add_header_above(header = c('Correlation Matrix' = 7))\n```\n\n## Pairwise Correlations\n\nAnother good option is to make pairwise plots. The diagonals show the \ndistribution of the variable, and in the second plot, the asterisks indicate\nthe significance of the relationship. \n\n```{r, echo = FALSE, warning=FALSE}\nlibrary(GGally)\nlibrary(PerformanceAnalytics)\n \n\nggpairs(energy_meta2[, -c(1, 2)])\nchart.Correlation(energy_meta2[, -c(1, 2)])\n\n```\n\n# Conclusions\n\n* Distribution across climate zones (kgcz and ashrae) is extremely skewed\n    + 75% of buildings in 2 kgcz and 85% in 2 ashrae cz\n    + More than 30 buildings in 3 different climate zones\n* Limited number of building areas and building types \n    + Accuracy is also an issue\n    + Shreyas is working on finding more but these are all estimates\n* Data cleaning improves the quality of data\n    + Most common change: BAAP -> AAAP\n* Heating type seems suspect based on geographical distribution\n    + Could potentially be an effect of building type\n    + Might need to rethink methodology/cutpoint for heating type\n* Effective Thermal Resistance needs to be modified (I'm on it!)\n    + Values are above any reasonable level as established in the literature\n* EUI Values are reasonable (we can't get this wrong!)\n* Temperature is highly positively correlated with energy consumption during the summer\n    + GHI also positively correlated, relative humidity negatively correlated\n* No significant winter weather correlations when average across climate zones\n* 91.3% of buildings have base peak savings opportunities during the winter\n* 83.9% of buildings have base peak savings opportunities during the summer\n* Buildings with more than 1 year: 45.5% improved base-peak ratio, 43.7% got worse,\n(rest had no change)\n* HVAC schedule produces reasonable results\n    + Starbucks begins much earlier than other companies\n    + Most buildings operate the HVAC between 9.5 and 12.5 hours per day\n* Summer base peak ratio and winter base peak ratio are highly correlated with r = 0.84\n    + This is expected and provides confidence in base peak ratio calculation\n* EUI and R value are negatively correlated with r = - 0.38\n    + This is expected because better insulated buildings should have a lower energy use per area\n* Summer base peak ratio and winter base peak ratio are mildy correlated with the log of annual consumption\n\n# Prediction Method\n\nIn order to meet [ARPA-E milestone 4.1.1](https://drive.google.com/open?id=0B5BHzqQ22JVYVjdfT3BYTS1sUE0), \nwe need to develop a predictive model\nthat achieves an adjusted R2 greater than 0.85 when predicting six months. \nI wanted to test a random forest regression model for predictive capability. \nThe details of the Random Forest are presented below, but the summary is the\nRandom Forest is an extremely powerful model that maintains a level of interpretability.\n\n## Random Forest Description\n\nThe [original paper describing Random Forests](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf) is by Leo Breiman.\n\nTo understand the powerful random forest, you first need to grasp the concept of a decision tree.\nThe best way to describe a single decision tree is as a flowchart of questions about the variable values\nof an observation\nthat leads in a classification/prediction. Each question (known as a node) has a yes/no answer based on the value of a particular variable.\nThe two answer form branches leading away from the node. Eventually, \nthe tree terminates in the final classification/prediction node called a leaf. \nA single decision tree can be arbitrarily large and deep depending on the number of features\nand the number of classes. They are adept at both classification and regression and \ncan learn a non-linear decision boundary (they actually learn many small linear \ndecision boundaries which collectively are non-linear). However, a single decision tree\nis very prone to overfitting, especially as the depth increases. The decision tree is flexible \nleading to a tendency to simply memorize the training data. To solve this problem, \nensembles of decision trees are combined into a powerful classifier known \nas a random forest. Each tree in the forest is trained on a randomly chosen subset of the \ntraining data (either with replacement, called bootstrapping, or without) and \n on a subset of the features. This increases variability between trees making\nthe overall forest more robust and less prone to overfitting. In order to make predictions,\nthe random forest passes the features (values of variables) of the observation to all trees, and takes an average \nof the votes of each tree (known as bagging). The random forest can also weight the votes \nof each tree with respect to the confidence the tree has in its prediction. Overall, \nthe random forest is fast, relatively simple, has a moderate level of interpretability,\nand performs extremely well on both classification and regression tasks. The random\nforest should be one of the first models tried on any machine learning problem and is generally my second approach after a linear model.\nThere are a number of hyperparameters that must be specified for the forest ahead of time\nwith the most important the number of trees in the forest, the number of features \nconsidered by each tree, the depth of the tree, and the minimum number of observations\npermitted at each leaf of the tree. These can be selected by training many different models\nwith varying hyperparameters and selecting the combination that performs \nbest on cross-validation or a testing set. A random forest performs implicit feature \nselection and can return the relative importances of the features so it can \nbe used as a method to reduce dimensions for additional algorithms.\n\nA simplified model of a decision tree used for exactly this task is presented below\n\n```{r, echo = FALSE}\nknitr::include_graphics('small_treevis.png')\n```\n\n## Methodology \n\nIn order to test the accuracy of the method, I trained the model on all data\nexcept for the final six months. I then took the final six months of data and \nmade predictions for the electricity consumption. These predictions were compared\nto the known true values to assess the predictive capabilites of the random forest.\nThis procedure was then completed for all buildings in HBase. \n\n## Results\n\nThe prediction capabilities of the model have been tested against all buildings \nin HBase with fewer than 1 million datapoints. The average runtime to train\nand predict for a building is around 4 minutes (depending on number of datapoints).\n\nWe can plot the rsquared and mape values to determine the performance. \nAround 25% of buildings currently have an r-squared above the requirement.\n\n```{r}\n# Read in results\nrf_results <- read_csv('../data/rf_results.csv')\n\n# Plot r-squared and mape\nggplot(rf_results, aes(x = leny, y = rsq, col = label)) + geom_jitter() +\n  scale_color_stata() + theme_hc(12) + xlab('Length of Dataset in Years') + \n  ylab('R - Squared') + ggtitle('R Squared vs Length of Dataset') + \n  labs(color = 'label') + geom_hline(yintercept = 0.85, col = 'red', lwd = 1.2) + \n  theme(plot.title = element_text(hjust = 0.5))\n\nggplot(dplyr::filter(rf_results, !is.infinite(mape), mape < 1), \n       aes(x = leny, y = mape * 100, col = label)) + geom_jitter() +\n  scale_color_stata() + theme_hc(12) + xlab('Length of Dataset in Years') + \n  ylab('mape') + ggtitle('MAPE vs Length of Dataset') + \n  labs(color = 'label')  + \n  theme(plot.title = element_text(hjust = 0.5))\n```\n\n### Typical Predictions\n\nThe following are predictions made for the Progressive APS building in Phoenix, Arizona.\nThe rsquared value for these predictions was 0.933.\n\n```{r, echo = FALSE}\n# Read in relevant true values and predictions\naps_train <- feather::read_feather('../data/feather/APS_y_train.feather')\naps_test  <- feather::read_feather('../data/feather/APS_y_test.feather')\n\naps_true <- rbind(aps_train, aps_test)\naps_true <- aps_true[, - which(names(aps_true) == 'cleaned_energy')]\nnames(aps_true)[2] <- 'value'\naps_true$set <- 'actual'\n\naps_pred <- feather::read_feather('../data/feather/APS_preds.feather')\nnames(aps_pred) <- 'value'\naps_pred$timestamp <- aps_test$timestamp\naps_pred$set <- 'pred'\n\naps_true <- rbind(aps_true, aps_pred)\n\n# Overall true and predicted values\nggplot(aps_true, aes(x = timestamp, y = value, col = set)) +\n  geom_line() + theme_tufte(12)  + \n  xlab('') + ylab('Energy (kWh)') + ggtitle('Example RF Predictions') + \n  scale_color_stata() + labs(color = '') + \n  theme(axis.text = element_text(color = 'black'),\n        plot.title = element_text(hjust = 0.5),\n        legend.position = 'bottom')\n\n# Weekly\naps_true$week <- lubridate::week(aps_true$timestamp)\n\naps_week <- aps_true[which(aps_true$week == 42), ]\naps_week$day <- lubridate::wday(label = TRUE, abbr = TRUE, aps_week$timestamp)\naps_week <- aps_week[which(lubridate::year(aps_week$timestamp) == 2016), ]\naps_week$time <- lubridate::hms(stringr::str_split_fixed(aps_week$timestamp, pattern = ' ', n = 2)[, 2])\n\nggplot(aps_week, \n       aes(x = round(as.numeric(time)/3600), y = value, col = set)) + \n  geom_line(size = 1.1) +\n  facet_grid(. ~ day) + xlab('Time of Day (hrs)') + ylab('Energy (kWh)') + \n  ggtitle('Weekly Random Forest Predictions') + \n  scale_x_continuous(breaks = seq(0, 24, 6)) + labs(color = '') + \n  theme_hc(12) + theme(axis.text = element_text(color = 'black'),\n                       plot.title = element_text(hjust = 0.5)) + \n  scale_color_stata()\n\n```\n\n# Animations\n\nAnimated graphs as a good way to highlight changes over time and can compress\na considerable amount of information into a single visual. I am not sure if these\nwill be useful, but at the least they are fun to make!\n\n## Weekly Seasonal Patterns\n\n![](2016_snapshot.gif)\n\n## Daily Patterns\n\n![](2016_daily.gif)\n\n## Year Long\n\n![](2016_full.gif)\n\n## Temperature and Energy Response Lag\n\n![](energy_and_temp.gif)\n\n\n```{r, eval = FALSE}\nlibrary(gganimate)\n\nframe <- sapply(c(1:40), rep, times = 20)\nframe <- as.numeric(gather(as.data.frame(frame))$value)\nframe <- frame[1:nrow(energy_meta)]\n\nkgcz_location <- dplyr::select(energy_meta, long, lati, kgcz)\nkgcz_location$num <- frame\nkgcz_location$lati <- as.numeric(kgcz_location$lati)\nkgcz_location$long <- as.numeric(kgcz_location$long)\n\np2 <- ggplot() + geom_polygon(data = us, aes(x = long, y = lat, group = group)) + \n  geom_polygon(fill = 'grey10') + coord_map() + theme_void() + \n  geom_point(data = kgcz_location, \n             aes(x = long, y = lati, frame = num, col = kgcz,\n                                       cumulative = TRUE), shape = 19, size = 12) + \n  theme(legend.position = 'bottom') + scale_color_stata()\n\ngganimate(p2, filename = 'map.gif', saver = 'gif', interval = 0.25, title_frame = FALSE,\n          ani.width = 1200, ani.height = 800)\n\n```\n",
    "created" : 1512916479508.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2270253560",
    "id" : "FD335B0B",
    "lastKnownWriteTime" : 1512918049,
    "last_content_update" : 1512918049576,
    "path" : "~/DSCI 451/cross-section_building_eda/scripts/mrk-building_eda_real.Rmd",
    "project_path" : null,
    "properties" : {
        "last_setup_crc32" : "559F29AF22d08815"
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}