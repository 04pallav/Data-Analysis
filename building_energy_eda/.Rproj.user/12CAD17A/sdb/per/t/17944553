{
    "collab_server" : "",
    "contents" : "# Modeling with a Random Forest\n# \n# \nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggthemes)\nlibrary(stats)\nlibrary(data.table)\nlibrary(car)\nlibrary(clusterSim)\nlibrary(randomForest)\nlibrary(caret)\nlibrary(feather)\nlibrary(Metrics)\nlibrary(dummies)\nlibrary(ranger)\n\n\n# Take in a dataframe in standard format and create training and testing sets \n# of final six months\nget_features_labels <- function(df) {\n  \n  df <- as.data.frame(df)\n  \n  # Enforce column specifications\n  # Create columns for day of the year, month, and year\n  df2 <- df %>% mutate(day = yday(timestamp), month = month(timestamp), \n                       year = year(timestamp)) %>%  \n    \n    # Transform cyclical features (month, day, num_time)\n    mutate(day_sin = sin(2 * day * pi / 365), \n           day_cos = cos(2 * day * pi / 365),\n           month_sin = sin(2 * month * pi / 12), \n           month_cos = cos(2 * month * pi / 12),\n           num_time_sin = sin(2 * num_time * pi / 24),\n           num_time_cos = cos(2 * num_time * pi / 24))\n  \n\n  df2$day_of_week <-  as.factor(df2$day_of_week)\n  df2$week_day_end <- as.factor(df2$week_day_end)\n  df2$sun_rise_set <- as.factor(df2$sun_rise_set)\n  \n  # One hot encoding of categorical variables\n  df2 <- dummy.data.frame(df2, names = c('day_of_week', 'week_day_end', 'sun_rise_set'), sep = '_') \n  \n  # Extract the known values, and timestamps for graphing\n  labels <- df2[c('timestamp', 'cleaned_energy', 'forecast')]\n  \n  cols_to_remove <- c('elec_cons', 'elec_cons_imp', 'pow_dem', 'cleaned_energy',\n                      'anom_flag', 'forecast', 'anom_missed_flag')\n  \n  # Change the timestamp to a numeric\n  df2$timestamp <- as.numeric(df2$timestamp)\n  \n  # Remove the columns from the features\n  df2 <- df2[, -which(names(df2) %in% cols_to_remove)]\n  \n  six_months_index <- nrow(df2) - (60 / as.numeric(df$timestamp[5] - df$timestamp[4])) * 24 * 180\n  \n  # Return the complete features and labels as testing and training sets\n  train_features <- df2[1:six_months_index - 1, ]\n  test_features <- df2[six_months_index:nrow(df2), ]\n  \n  # Scale features\n  \n  pre_processor <- caret::preProcess(train_features, method = c('center', 'scale'))\n  \n  train_features <- predict(pre_processor, train_features)\n  test_features <- predict(pre_processor, test_features)\n  \n  train_labels <- labels[1:six_months_index - 1, ]\n  test_labels <- labels[six_months_index:nrow(df2), ]\n  \n  return(list('X_train' = train_features, 'X_test' = test_features, \n              'y_train' = train_labels, 'y_test' = test_labels))\n}\n\n# Function to train and evaluate a random forest model on an energy dataframe\n# Dataframe is first passed to the feature and labels function\ntrain_rf <- function(df) {\n  \n  features_labels <- get_features_labels(df)\n  \n  X_train <- features_labels$X_train\n  X_test <- features_labels$X_test\n  \n  y_train <- dplyr::select(features_labels$y_train, forecast)\n  y_test <- dplyr::select(features_labels$y_test, forecast)\n  \n  train <- cbind(X_train, y_train)\n  test <- cbind(X_test, y_test)\n\n  # grid <- expand.grid(mtry = c(15, 20, 25),\n  #                     splitrule = c('variance', 'extratrees'))\n  # \n  # control <- trainControl(method = 'cv', number = 3, search = 'grid', verboseIter = TRUE)\n  # \n  # # Create the random forest model\n  # rf <- train(forecast ~ ., data = train, method = 'ranger', trControl = control, \n  #             tuneGrid = grid)\n  #             \n  rf <- ranger(forecast ~ ., data = train, num.trees = 100,\n               min.node.size = 3, splitrule = 'variance', verbose = TRUE)\n  \n  pred <- predict(rf, test)\n  \n  rmse <- sqrt(mean((pred$predictions - y_test$forecast) ^ 2))\n  rsq <- cor(pred$predictions, y_test$forecast) ^ 2\n  mape <- abs(mean((pred$predictions - y_test$forecast) / y_test$forecast))\n  \n  return(list('rmse' = rmse, 'rsq' = rsq, 'mape' = mape))\n  \n}\n\nprogressive <- dir('data/')[startsWith(dir('data/'), 'f-')]\n\nmetrics <- as.data.frame(matrix(ncol = 4))\nnames(metrics) <- c('building', 'rmse', 'rsq', 'mape')\n\nfor (file in progressive) { \n  name <- unlist(strsplit(file, '-|_'))[2]\n  df <- read_csv(paste0('data/', file))\n  df_metrics <- train_rf(df)\n  \n  metrics <- add_row(metrics, building = name, rmse = df_metrics$rmse, \n                     rsq = df_metrics$rsq, mape = df_metrics$mape)\n}\n\nmetrics_var_kept <- metrics\n\nsummary(metrics_var_kept)\nsummary(metrics_var_removed)\n",
    "created" : 1512916440461.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2225666765",
    "id" : "17944553",
    "lastKnownWriteTime" : 1512518312,
    "last_content_update" : 1512518312,
    "path" : "~/DSCI 451/cross-section_building_eda/scripts/random_forest.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}